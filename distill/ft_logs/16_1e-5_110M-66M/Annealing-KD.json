[
    {
      "args": {
        "save": "../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd/ft_annealing_kd/ReCoRD/blank-tiny6-ReCoRD-221127_131103.758648",
        "epochs": 5,
        "iteration": 43385,
        "task": "ReCoRD",
        "wsc_negative": false
      },
      "now": "2022-11-28 00:36:31.924560",
      "max_score_dict": {
        "EM": {
          "epoch": 3,
          "iteration": 34708,
          "score_dict": {
            "EM": 55.11,
            "F1": 55.84892207792214
          }
        },
        "F1": {
          "epoch": 3,
          "iteration": 34708,
          "score_dict": {
            "EM": 55.11,
            "F1": 55.84892207792214
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=50613 --include=localhost:1 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-ReCoRD-221127_131103.758648 --task=ReCoRD --data-dir=../GLM/data/english_data/superglue/ReCoRD --save=../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd/ft_annealing_kd/ReCoRD --seq-length=512 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained=../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --pattern-id=0 --save-interval=10000 --log-interval=50 --eval-interval=1000 --eval-iters=100 --batch-size=16 --epochs=5 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=config_tasks/config_blocklm_tiny6.json --student_model=annealing_kd --annealing_kd_max_t=7 --distill_ft_soft --distill_ft_soft_mse --seed=1234 --teacher_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/ReCoRD/blank-base-ReCoRD-220813_083745 --teacher_num_layers=12 --teacher_hidden_size=768 --teacher_num_attention_heads=12 --teacher_max_position_embeddings=512 --teacher_fp16 --custom_tmp_result=../GLM/data/tmp/result_221127_131104.862894.json"
    },
    {
      "args": {
        "save": "../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd/ft_annealing_kd/ReCoRD/blank-tiny6-ReCoRD-221127_131103.758648/ft_annealing_kd/ReCoRD/blank-tiny6-ReCoRD-221127_131104.860981",
        "epochs": 5,
        "iteration": 43385,
        "task": "ReCoRD",
        "wsc_negative": false
      },
      "now": "2022-11-28 12:02:01.425848",
      "max_score_dict": {
        "EM": {
          "epoch": 0,
          "iteration": 0,
          "score_dict": {
            "EM": 55.11,
            "F1": 55.84892207792214
          }
        },
        "F1": {
          "epoch": 0,
          "iteration": 0,
          "score_dict": {
            "EM": 55.11,
            "F1": 55.84892207792214
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=26681 --include=localhost:1 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-ReCoRD-221127_131104.860981 --task=ReCoRD --data-dir=../GLM/data/english_data/superglue/ReCoRD --save=../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd/ft_annealing_kd/ReCoRD/blank-tiny6-ReCoRD-221127_131103.758648/ft_annealing_kd/ReCoRD --seq-length=512 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained=../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd/ft_annealing_kd/ReCoRD/blank-tiny6-ReCoRD-221127_131103.758648 --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --pattern-id=0 --save-interval=10000 --log-interval=50 --eval-interval=1000 --eval-iters=100 --batch-size=16 --epochs=5 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=config_tasks/config_blocklm_tiny6.json --teacher_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/ReCoRD/blank-base-ReCoRD-220813_083745 --teacher_num_layers=12 --teacher_hidden_size=768 --teacher_num_attention_heads=12 --teacher_max_position_embeddings=512 --teacher_fp16 --student_model=annealing_kd --annealing_kd_max_t=7 --distill_ft_soft_mse --seed=1234 --distill_ft_hard --custom_first_eval --custom_tmp_result=../GLM/data/tmp/result_221128_003635.231990.json"
    },
    {
      "args": {
        "save": "../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd/ft_annealing_kd/COPA/blank-tiny6-COPA-221128_120206.736566",
        "epochs": 50,
        "iteration": 2500,
        "task": "COPA",
        "wsc_negative": false
      },
      "now": "2022-11-28 12:07:41.977360",
      "max_score_dict": {
        "accuracy": {
          "epoch": 7,
          "iteration": 400,
          "score_dict": {
            "accuracy": 66.0
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=34474 --include=localhost:1 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-COPA-221128_120206.736566 --task=COPA --data-dir=../GLM/data/english_data/superglue/COPA --save=../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd/ft_annealing_kd/COPA --seq-length=256 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained=../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --pattern-id=0 --save-interval=10000 --log-interval=20 --eval-interval=1000 --eval-iters=100 --batch-size=16 --epochs=50 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=config_tasks/config_blocklm_tiny6.json --student_model=annealing_kd --annealing_kd_max_t=7 --distill_ft_soft --distill_ft_soft_mse --seed=1234 --teacher_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/COPA/blank-base-COPA-220813_064749 --teacher_num_layers=12 --teacher_hidden_size=768 --teacher_num_attention_heads=12 --teacher_max_position_embeddings=512 --teacher_fp16 --custom_tmp_result=../GLM/data/tmp/result_221128_120207.839654.json"
    },
    {
      "args": {
        "save": "../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd/ft_annealing_kd/COPA/blank-tiny6-COPA-221128_120206.736566/ft_annealing_kd/COPA/blank-tiny6-COPA-221128_120207.838313",
        "epochs": 50,
        "iteration": 2500,
        "task": "COPA",
        "wsc_negative": false
      },
      "now": "2022-11-28 12:13:13.662476",
      "max_score_dict": {
        "accuracy": {
          "epoch": 0,
          "iteration": 0,
          "score_dict": {
            "accuracy": 66.0
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=28584 --include=localhost:1 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-COPA-221128_120207.838313 --task=COPA --data-dir=../GLM/data/english_data/superglue/COPA --save=../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd/ft_annealing_kd/COPA/blank-tiny6-COPA-221128_120206.736566/ft_annealing_kd/COPA --seq-length=256 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained=../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd/ft_annealing_kd/COPA/blank-tiny6-COPA-221128_120206.736566 --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --pattern-id=0 --save-interval=10000 --log-interval=20 --eval-interval=1000 --eval-iters=100 --batch-size=16 --epochs=50 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=config_tasks/config_blocklm_tiny6.json --teacher_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/COPA/blank-base-COPA-220813_064749 --teacher_num_layers=12 --teacher_hidden_size=768 --teacher_num_attention_heads=12 --teacher_max_position_embeddings=512 --teacher_fp16 --student_model=annealing_kd --annealing_kd_max_t=7 --distill_ft_soft_mse --seed=1234 --distill_ft_hard --custom_first_eval --custom_tmp_result=../GLM/data/tmp/result_221128_120744.514455.json"
    },
    {
      "args": {
        "save": "../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd/ft_annealing_kd/WSC/blank-tiny6-WSC-221128_121316.612927",
        "epochs": 50,
        "iteration": 1000,
        "task": "WSC",
        "wsc_negative": true
      },
      "now": "2022-11-28 12:17:45.841606",
      "max_score_dict": {
        "accuracy": {
          "epoch": 36,
          "iteration": 740,
          "score_dict": {
            "accuracy": 64.42307692307692
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=41756 --include=localhost:1 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-WSC-221128_121316.612927 --task=WSC --data-dir=../GLM/data/english_data/superglue/WSC-negative --save=../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd/ft_annealing_kd/WSC --seq-length=128 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained=../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --loss-func=mix --wsc-negative --length-penalty=1 --pattern-id=2 --save-interval=10000 --log-interval=50 --eval-interval=1000 --eval-iters=100 --batch-size=16 --epochs=50 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=config_tasks/config_blocklm_tiny6.json --student_model=annealing_kd --annealing_kd_max_t=7 --distill_ft_soft --distill_ft_soft_mse --seed=1234 --teacher_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/WSC/blank-base-WSC-220813_073441 --teacher_num_layers=12 --teacher_hidden_size=768 --teacher_num_attention_heads=12 --teacher_max_position_embeddings=512 --teacher_fp16 --custom_tmp_result=../GLM/data/tmp/result_221128_121317.715633.json"
    },
    {
      "args": {
        "save": "../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd/ft_annealing_kd/WSC/blank-tiny6-WSC-221128_121316.612927/ft_annealing_kd/WSC/blank-tiny6-WSC-221128_121317.714328",
        "epochs": 50,
        "iteration": 1000,
        "task": "WSC",
        "wsc_negative": true
      },
      "now": "2022-11-28 12:22:17.425117",
      "max_score_dict": {
        "accuracy": {
          "epoch": 0,
          "iteration": 0,
          "score_dict": {
            "accuracy": 64.42307692307692
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=39557 --include=localhost:1 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-WSC-221128_121317.714328 --task=WSC --data-dir=../GLM/data/english_data/superglue/WSC-negative --save=../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd/ft_annealing_kd/WSC/blank-tiny6-WSC-221128_121316.612927/ft_annealing_kd/WSC --seq-length=128 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained=../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd/ft_annealing_kd/WSC/blank-tiny6-WSC-221128_121316.612927 --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --loss-func=mix --wsc-negative --length-penalty=1 --pattern-id=2 --save-interval=10000 --log-interval=50 --eval-interval=1000 --eval-iters=100 --batch-size=16 --epochs=50 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=config_tasks/config_blocklm_tiny6.json --teacher_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/WSC/blank-base-WSC-220813_073441 --teacher_num_layers=12 --teacher_hidden_size=768 --teacher_num_attention_heads=12 --teacher_max_position_embeddings=512 --teacher_fp16 --student_model=annealing_kd --annealing_kd_max_t=7 --distill_ft_soft_mse --seed=1234 --distill_ft_hard --custom_first_eval --custom_tmp_result=../GLM/data/tmp/result_221128_121748.714821.json"
    },
    {
      "args": {
        "save": "../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd/ft_annealing_kd/RTE/blank-tiny6-RTE-221128_122219.878943",
        "epochs": 50,
        "iteration": 7800,
        "task": "RTE",
        "wsc_negative": false
      },
      "now": "2022-11-28 12:31:03.196935",
      "max_score_dict": {
        "accuracy": {
          "epoch": 25,
          "iteration": 4056,
          "score_dict": {
            "accuracy": 59.2057761732852
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=10754 --include=localhost:1 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-RTE-221128_122219.878943 --task=RTE --data-dir=../GLM/data/english_data/superglue/RTE --save=../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd/ft_annealing_kd/RTE --seq-length=256 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained=../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --pattern-id=0 --save-interval=10000 --log-interval=50 --eval-interval=10000000 --eval-iters=100 --batch-size=16 --epochs=50 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=config_tasks/config_blocklm_tiny6.json --student_model=annealing_kd --annealing_kd_max_t=7 --distill_ft_soft --distill_ft_soft_mse --seed=1234 --teacher_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/RTE/blank-base-RTE-220813_065724 --teacher_num_layers=12 --teacher_hidden_size=768 --teacher_num_attention_heads=12 --teacher_max_position_embeddings=512 --teacher_fp16 --custom_tmp_result=../GLM/data/tmp/result_221128_122220.981650.json"
    },
    {
      "args": {
        "save": "../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd/ft_annealing_kd/RTE/blank-tiny6-RTE-221128_122219.878943/ft_annealing_kd/RTE/blank-tiny6-RTE-221128_122220.980383",
        "epochs": 50,
        "iteration": 7800,
        "task": "RTE",
        "wsc_negative": false
      },
      "now": "2022-11-28 12:39:45.130865",
      "max_score_dict": {
        "accuracy": {
          "epoch": 0,
          "iteration": 0,
          "score_dict": {
            "accuracy": 59.2057761732852
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=26238 --include=localhost:1 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-RTE-221128_122220.980383 --task=RTE --data-dir=../GLM/data/english_data/superglue/RTE --save=../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd/ft_annealing_kd/RTE/blank-tiny6-RTE-221128_122219.878943/ft_annealing_kd/RTE --seq-length=256 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained=../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd/ft_annealing_kd/RTE/blank-tiny6-RTE-221128_122219.878943 --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --pattern-id=0 --save-interval=10000 --log-interval=50 --eval-interval=10000000 --eval-iters=100 --batch-size=16 --epochs=50 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=config_tasks/config_blocklm_tiny6.json --teacher_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/RTE/blank-base-RTE-220813_065724 --teacher_num_layers=12 --teacher_hidden_size=768 --teacher_num_attention_heads=12 --teacher_max_position_embeddings=512 --teacher_fp16 --student_model=annealing_kd --annealing_kd_max_t=7 --distill_ft_soft_mse --seed=1234 --distill_ft_hard --custom_first_eval --custom_tmp_result=../GLM/data/tmp/result_221128_123105.420608.json"
    },
    {
      "args": {
        "save": "../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd/ft_annealing_kd/BoolQ/blank-tiny6-BoolQ-221128_123947.829310",
        "epochs": 20,
        "iteration": 11800,
        "task": "BoolQ",
        "wsc_negative": false
      },
      "now": "2022-11-28 12:53:04.094515",
      "max_score_dict": {
        "accuracy": {
          "epoch": 18,
          "iteration": 11210,
          "score_dict": {
            "accuracy": 71.46788990825688
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=56867 --include=localhost:1 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-BoolQ-221128_123947.829310 --task=BoolQ --data-dir=../GLM/data/english_data/superglue/BoolQ --save=../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd/ft_annealing_kd/BoolQ --seq-length=256 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained=../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --pattern-id=4 --save-interval=10000 --log-interval=50 --eval-interval=10000000 --eval-iters=100 --batch-size=16 --epochs=20 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=config_tasks/config_blocklm_tiny6.json --student_model=annealing_kd --annealing_kd_max_t=7 --distill_ft_soft --distill_ft_soft_mse --seed=1234 --teacher_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/BoolQ/blank-base-BoolQ-220813_070712 --teacher_num_layers=12 --teacher_hidden_size=768 --teacher_num_attention_heads=12 --teacher_max_position_embeddings=512 --teacher_fp16 --custom_tmp_result=../GLM/data/tmp/result_221128_123948.931134.json"
    },
    {
      "args": {
        "save": "../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd/ft_annealing_kd/BoolQ/blank-tiny6-BoolQ-221128_123947.829310/ft_annealing_kd/BoolQ/blank-tiny6-BoolQ-221128_123948.930226",
        "epochs": 20,
        "iteration": 11800,
        "task": "BoolQ",
        "wsc_negative": false
      },
      "now": "2022-11-28 13:06:20.673608",
      "max_score_dict": {
        "accuracy": {
          "epoch": 8,
          "iteration": 5310,
          "score_dict": {
            "accuracy": 71.62079510703364
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=29604 --include=localhost:1 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-BoolQ-221128_123948.930226 --task=BoolQ --data-dir=../GLM/data/english_data/superglue/BoolQ --save=../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd/ft_annealing_kd/BoolQ/blank-tiny6-BoolQ-221128_123947.829310/ft_annealing_kd/BoolQ --seq-length=256 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained=../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd/ft_annealing_kd/BoolQ/blank-tiny6-BoolQ-221128_123947.829310 --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --pattern-id=4 --save-interval=10000 --log-interval=50 --eval-interval=10000000 --eval-iters=100 --batch-size=16 --epochs=20 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=config_tasks/config_blocklm_tiny6.json --teacher_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/BoolQ/blank-base-BoolQ-220813_070712 --teacher_num_layers=12 --teacher_hidden_size=768 --teacher_num_attention_heads=12 --teacher_max_position_embeddings=512 --teacher_fp16 --student_model=annealing_kd --annealing_kd_max_t=7 --distill_ft_soft_mse --seed=1234 --distill_ft_hard --custom_first_eval --custom_tmp_result=../GLM/data/tmp/result_221128_125307.176442.json"
    },
    {
      "args": {
        "save": "../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd/ft_annealing_kd/WiC/blank-tiny6-WiC-221128_130623.788443",
        "epochs": 30,
        "iteration": 10200,
        "task": "WiC",
        "wsc_negative": false
      },
      "now": "2022-11-28 13:17:15.879162",
      "max_score_dict": {
        "accuracy": {
          "epoch": 18,
          "iteration": 6460,
          "score_dict": {
            "accuracy": 58.46394984326019
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=16045 --include=localhost:1 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-WiC-221128_130623.788443 --task=WiC --data-dir=../GLM/data/english_data/superglue/WiC --save=../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd/ft_annealing_kd/WiC --seq-length=256 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained=../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --pattern-id=1 --save-interval=10000 --log-interval=50 --eval-interval=10000000 --eval-iters=100 --batch-size=16 --epochs=30 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=config_tasks/config_blocklm_tiny6.json --student_model=annealing_kd --annealing_kd_max_t=7 --distill_ft_soft --distill_ft_soft_mse --seed=1234 --teacher_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/WiC/blank-base-WiC-220813_072213 --teacher_num_layers=12 --teacher_hidden_size=768 --teacher_num_attention_heads=12 --teacher_max_position_embeddings=512 --teacher_fp16 --custom_tmp_result=../GLM/data/tmp/result_221128_130624.890896.json"
    },
    {
      "args": {
        "save": "../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd/ft_annealing_kd/WiC/blank-tiny6-WiC-221128_130623.788443/ft_annealing_kd/WiC/blank-tiny6-WiC-221128_130624.889818",
        "epochs": 30,
        "iteration": 10200,
        "task": "WiC",
        "wsc_negative": false
      },
      "now": "2022-11-28 13:28:15.786701",
      "max_score_dict": {
        "accuracy": {
          "epoch": 0,
          "iteration": 0,
          "score_dict": {
            "accuracy": 58.46394984326019
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=55780 --include=localhost:1 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-WiC-221128_130624.889818 --task=WiC --data-dir=../GLM/data/english_data/superglue/WiC --save=../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd/ft_annealing_kd/WiC/blank-tiny6-WiC-221128_130623.788443/ft_annealing_kd/WiC --seq-length=256 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained=../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd/ft_annealing_kd/WiC/blank-tiny6-WiC-221128_130623.788443 --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --pattern-id=1 --save-interval=10000 --log-interval=50 --eval-interval=10000000 --eval-iters=100 --batch-size=16 --epochs=30 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=config_tasks/config_blocklm_tiny6.json --teacher_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/WiC/blank-base-WiC-220813_072213 --teacher_num_layers=12 --teacher_hidden_size=768 --teacher_num_attention_heads=12 --teacher_max_position_embeddings=512 --teacher_fp16 --student_model=annealing_kd --annealing_kd_max_t=7 --distill_ft_soft_mse --seed=1234 --distill_ft_hard --custom_first_eval --custom_tmp_result=../GLM/data/tmp/result_221128_131718.946724.json"
    },
    {
      "args": {
        "save": "../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd/ft_annealing_kd/CB/blank-tiny6-CB-221128_132818.222028",
        "epochs": 50,
        "iteration": 800,
        "task": "CB",
        "wsc_negative": false
      },
      "now": "2022-11-28 13:29:55.601260",
      "max_score_dict": {
        "accuracy": {
          "epoch": 29,
          "iteration": 480,
          "score_dict": {
            "accuracy": 83.92857142857143,
            "f1-macro": 0.8201893424769792
          }
        },
        "f1-macro": {
          "epoch": 22,
          "iteration": 368,
          "score_dict": {
            "accuracy": 82.14285714285714,
            "f1-macro": 0.8220454236366109
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=58411 --include=localhost:1 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-CB-221128_132818.222028 --task=CB --data-dir=../GLM/data/english_data/superglue/CB --save=../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd/ft_annealing_kd/CB --seq-length=256 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained=../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --pattern-id=3 --save-interval=10000 --log-interval=50 --eval-interval=10000000 --eval-iters=100 --batch-size=16 --epochs=50 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=config_tasks/config_blocklm_tiny6.json --student_model=annealing_kd --annealing_kd_max_t=7 --distill_ft_soft --distill_ft_soft_mse --seed=1234 --teacher_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/CB/blank-base-CB-220813_065532 --teacher_num_layers=12 --teacher_hidden_size=768 --teacher_num_attention_heads=12 --teacher_max_position_embeddings=512 --teacher_fp16 --custom_tmp_result=../GLM/data/tmp/result_221128_132819.324673.json"
    },
    {
      "args": {
        "save": "../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd/ft_annealing_kd/CB/blank-tiny6-CB-221128_132818.222028/ft_annealing_kd/CB/blank-tiny6-CB-221128_132819.323381",
        "epochs": 50,
        "iteration": 800,
        "task": "CB",
        "wsc_negative": false
      },
      "now": "2022-11-28 13:31:31.805909",
      "max_score_dict": {
        "accuracy": {
          "epoch": 6,
          "iteration": 112,
          "score_dict": {
            "accuracy": 87.5,
            "f1-macro": 0.8789378057302587
          }
        },
        "f1-macro": {
          "epoch": 6,
          "iteration": 112,
          "score_dict": {
            "accuracy": 87.5,
            "f1-macro": 0.8789378057302587
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=54195 --include=localhost:1 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-CB-221128_132819.323381 --task=CB --data-dir=../GLM/data/english_data/superglue/CB --save=../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd/ft_annealing_kd/CB/blank-tiny6-CB-221128_132818.222028/ft_annealing_kd/CB --seq-length=256 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained=../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd/ft_annealing_kd/CB/blank-tiny6-CB-221128_132818.222028 --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --pattern-id=3 --save-interval=10000 --log-interval=50 --eval-interval=10000000 --eval-iters=100 --batch-size=16 --epochs=50 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=config_tasks/config_blocklm_tiny6.json --teacher_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/CB/blank-base-CB-220813_065532 --teacher_num_layers=12 --teacher_hidden_size=768 --teacher_num_attention_heads=12 --teacher_max_position_embeddings=512 --teacher_fp16 --student_model=annealing_kd --annealing_kd_max_t=7 --distill_ft_soft_mse --seed=1234 --distill_ft_hard --custom_first_eval --custom_tmp_result=../GLM/data/tmp/result_221128_133000.508129.json"
    },
    {
      "args": {
        "save": "../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd/ft_annealing_kd/MultiRC/blank-tiny6-MultiRC-221128_133135.758357",
        "epochs": 15,
        "iteration": 25545,
        "task": "MultiRC",
        "wsc_negative": false
      },
      "now": "2022-11-28 14:21:08.166921",
      "max_score_dict": {
        "f1a": {
          "epoch": 8,
          "iteration": 15327,
          "score_dict": {
            "f1a": 0.661296984717059,
            "em": 0.12067156348373557,
            "acc": 66.17161716171617
          }
        },
        "em": {
          "epoch": 2,
          "iteration": 5109,
          "score_dict": {
            "f1a": 0.6483516483516484,
            "em": 0.16054564533053514,
            "acc": 68.31683168316832
          }
        },
        "acc": {
          "epoch": 2,
          "iteration": 5109,
          "score_dict": {
            "f1a": 0.6483516483516484,
            "em": 0.16054564533053514,
            "acc": 68.31683168316832
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=46053 --include=localhost:1 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-MultiRC-221128_133135.758357 --task=MultiRC --data-dir=../GLM/data/english_data/superglue/MultiRC --save=../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd/ft_annealing_kd/MultiRC --seq-length=512 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained=../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --pattern-id=0 --save-interval=10000 --log-interval=50 --eval-interval=10000000 --eval-iters=100 --batch-size=16 --epochs=15 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=config_tasks/config_blocklm_tiny6.json --student_model=annealing_kd --annealing_kd_max_t=7 --distill_ft_soft --distill_ft_soft_mse --seed=1234 --teacher_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/MultiRC/blank-base-MultiRC-220813_074014 --teacher_num_layers=12 --teacher_hidden_size=768 --teacher_num_attention_heads=12 --teacher_max_position_embeddings=512 --teacher_fp16 --custom_tmp_result=../GLM/data/tmp/result_221128_133136.861259.json"
    },
    {
      "args": {
        "save": "../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd/ft_annealing_kd/MultiRC/blank-tiny6-MultiRC-221128_133135.758357/ft_annealing_kd/MultiRC/blank-tiny6-MultiRC-221128_133136.859957",
        "epochs": 15,
        "iteration": 25545,
        "task": "MultiRC",
        "wsc_negative": false
      },
      "now": "2022-11-28 15:10:33.492654",
      "max_score_dict": {
        "f1a": {
          "epoch": 0,
          "iteration": 0,
          "score_dict": {
            "f1a": 0.661296984717059,
            "em": 0.12067156348373557,
            "acc": 66.17161716171617
          }
        },
        "em": {
          "epoch": 10,
          "iteration": 18733,
          "score_dict": {
            "f1a": 0.6444933920704846,
            "em": 0.1385099685204617,
            "acc": 66.70792079207921
          }
        },
        "acc": {
          "epoch": 2,
          "iteration": 5109,
          "score_dict": {
            "f1a": 0.6289308176100629,
            "em": 0.13431269674711438,
            "acc": 67.14108910891089
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=19614 --include=localhost:1 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-MultiRC-221128_133136.859957 --task=MultiRC --data-dir=../GLM/data/english_data/superglue/MultiRC --save=../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd/ft_annealing_kd/MultiRC/blank-tiny6-MultiRC-221128_133135.758357/ft_annealing_kd/MultiRC --seq-length=512 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained=../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd/ft_annealing_kd/MultiRC/blank-tiny6-MultiRC-221128_133135.758357 --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --pattern-id=0 --save-interval=10000 --log-interval=50 --eval-interval=10000000 --eval-iters=100 --batch-size=16 --epochs=15 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=config_tasks/config_blocklm_tiny6.json --teacher_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/MultiRC/blank-base-MultiRC-220813_074014 --teacher_num_layers=12 --teacher_hidden_size=768 --teacher_num_attention_heads=12 --teacher_max_position_embeddings=512 --teacher_fp16 --student_model=annealing_kd --annealing_kd_max_t=7 --distill_ft_soft_mse --seed=1234 --distill_ft_hard --custom_first_eval --custom_tmp_result=../GLM/data/tmp/result_221128_142111.743551.json"
    },
    {
      "args": {
        "save": "../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd/ft_annealing_kd/WSC/blank-tiny6-WSC_generative-221128_151035.824302",
        "epochs": 50,
        "iteration": 850,
        "task": "WSC",
        "wsc_negative": false
      },
      "now": "2022-11-28 15:12:01.321257",
      "max_score_dict": {
        "accuracy": {
          "epoch": 0,
          "iteration": 17,
          "score_dict": {
            "accuracy": 63.46153846153846
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=53212 --include=localhost:1 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-WSC_generative-221128_151035.824302 --task=WSC --data-dir=../GLM/data/english_data/superglue/WSC --save=../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd/ft_annealing_kd/WSC --seq-length=128 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained=../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --save-interval=10000 --log-interval=50 --eval-interval=1000 --eval-iters=100 --batch-size=16 --epochs=50 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=config_tasks/config_blocklm_tiny6.json --student_model=annealing_kd --annealing_kd_max_t=7 --distill_ft_soft --distill_ft_soft_mse --seed=1234 --teacher_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/WSC/blank-base-WSC_generative-220813_065345 --teacher_num_layers=12 --teacher_hidden_size=768 --teacher_num_attention_heads=12 --teacher_max_position_embeddings=512 --teacher_fp16 --custom_tmp_result=../GLM/data/tmp/result_221128_151036.927253.json"
    },
    {
      "args": {
        "save": "../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd/ft_annealing_kd/WSC/blank-tiny6-WSC_generative-221128_151035.824302/ft_annealing_kd/WSC/blank-tiny6-WSC_generative-221128_151036.925919",
        "epochs": 50,
        "iteration": 850,
        "task": "WSC",
        "wsc_negative": false
      },
      "now": "2022-11-28 15:13:28.663394",
      "max_score_dict": {
        "accuracy": {
          "epoch": 12,
          "iteration": 221,
          "score_dict": {
            "accuracy": 65.38461538461539
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=58570 --include=localhost:1 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-WSC_generative-221128_151036.925919 --task=WSC --data-dir=../GLM/data/english_data/superglue/WSC --save=../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd/ft_annealing_kd/WSC/blank-tiny6-WSC_generative-221128_151035.824302/ft_annealing_kd/WSC --seq-length=128 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained=../GLM/data/checkpoints/distill/paper/6.768_64-15w_pd/ft_annealing_kd/WSC/blank-tiny6-WSC_generative-221128_151035.824302 --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --save-interval=10000 --log-interval=50 --eval-interval=1000 --eval-iters=100 --batch-size=16 --epochs=50 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=config_tasks/config_blocklm_tiny6.json --teacher_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/WSC/blank-base-WSC_generative-220813_065345 --teacher_num_layers=12 --teacher_hidden_size=768 --teacher_num_attention_heads=12 --teacher_max_position_embeddings=512 --teacher_fp16 --student_model=annealing_kd --annealing_kd_max_t=7 --distill_ft_soft_mse --seed=1234 --distill_ft_hard --custom_first_eval --custom_tmp_result=../GLM/data/tmp/result_221128_151204.687276.json"
    }
  ]