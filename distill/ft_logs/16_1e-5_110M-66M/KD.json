[
  {
    "args": {
      "save": "../GLM/data/checkpoints/pretrain/blocklm-base-blank/ft_kd/ReCoRD/blank-tiny6-ReCoRD-221031_221521.315119",
      "epochs": 5,
      "iteration": 43385,
      "task": "ReCoRD",
      "wsc_negative": false
    },
    "now": "2022-11-01 05:11:51.872630",
    "max_score_dict": {
      "EM": {
        "epoch": 3,
        "iteration": 34708,
        "score_dict": {
          "EM": 21.62,
          "F1": 22.397904761904766
        }
      },
      "F1": {
        "epoch": 3,
        "iteration": 34708,
        "score_dict": {
          "EM": 21.62,
          "F1": 22.397904761904766
        }
      }
    },
    "epoch": -1,
    "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=21047 --include=localhost:2,3 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-ReCoRD-221031_221521.315119 --task=ReCoRD --data-dir=../GLM/data/english_data/superglue/ReCoRD --save=../GLM/data/checkpoints/pretrain/blocklm-base-blank/ft_kd/ReCoRD --seq-length=512 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained= --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --pattern-id=0 --save-interval=10000 --log-interval=50 --eval-interval=1000 --eval-iters=100 --batch-size=8 --epochs=5 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=tmp_deepspeed_config/221031_221521.316072_469630023037684.json --student_model=kd --distill_ft_soft --distill_ft_hard --distill_temperature=10 --seed=1234 --teacher_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/ReCoRD/blank-base-ReCoRD-220813_083745 --teacher_num_layers=12 --teacher_hidden_size=768 --teacher_num_attention_heads=12 --teacher_max_position_embeddings=512 --teacher_fp16 --custom_tmp_result=../GLM/data/tmp/result_221031_221521.317489.json"
  },
  {
    "args": {
      "save": "../GLM/data/checkpoints/pretrain/blocklm-base-blank/ft_kd/COPA/blank-tiny6-COPA-221101_051156.242513",
      "epochs": 50,
      "iteration": 2500,
      "task": "COPA",
      "wsc_negative": false
    },
    "now": "2022-11-01 05:16:48.967984",
    "max_score_dict": {
      "accuracy": {
        "epoch": 1,
        "iteration": 100,
        "score_dict": {
          "accuracy": 60.0
        }
      }
    },
    "epoch": -1,
    "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=22025 --include=localhost:2,3 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-COPA-221101_051156.242513 --task=COPA --data-dir=../GLM/data/english_data/superglue/COPA --save=../GLM/data/checkpoints/pretrain/blocklm-base-blank/ft_kd/COPA --seq-length=256 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained= --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --pattern-id=0 --save-interval=10000 --log-interval=20 --eval-interval=1000 --eval-iters=100 --batch-size=8 --epochs=50 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=tmp_deepspeed_config/221101_051156.243564_8643049826399087.json --student_model=kd --distill_ft_soft --distill_ft_hard --distill_temperature=10 --seed=1234 --teacher_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/COPA/blank-base-COPA-220813_064749 --teacher_num_layers=12 --teacher_hidden_size=768 --teacher_num_attention_heads=12 --teacher_max_position_embeddings=512 --teacher_fp16 --custom_tmp_result=../GLM/data/tmp/result_221101_051156.245401.json"
  },
  {
    "args": {
      "save": "../GLM/data/checkpoints/pretrain/blocklm-base-blank/ft_kd/WSC/blank-tiny6-WSC-221101_051652.308406",
      "epochs": 50,
      "iteration": 1000,
      "task": "WSC",
      "wsc_negative": true
    },
    "now": "2022-11-01 05:20:32.868356",
    "max_score_dict": {
      "accuracy": {
        "epoch": 0,
        "iteration": 20,
        "score_dict": {
          "accuracy": 62.5
        }
      }
    },
    "epoch": -1,
    "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=23752 --include=localhost:2,3 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-WSC-221101_051652.308406 --task=WSC --data-dir=../GLM/data/english_data/superglue/WSC-negative --save=../GLM/data/checkpoints/pretrain/blocklm-base-blank/ft_kd/WSC --seq-length=128 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained= --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --loss-func=mix --wsc-negative --length-penalty=1 --pattern-id=2 --save-interval=10000 --log-interval=50 --eval-interval=1000 --eval-iters=100 --batch-size=8 --epochs=50 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=tmp_deepspeed_config/221101_051652.309650_21320204963453626.json --student_model=kd --distill_ft_soft --distill_ft_hard --distill_temperature=10 --seed=1234 --teacher_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/WSC/blank-base-WSC-220813_073441 --teacher_num_layers=12 --teacher_hidden_size=768 --teacher_num_attention_heads=12 --teacher_max_position_embeddings=512 --teacher_fp16 --custom_tmp_result=../GLM/data/tmp/result_221101_051652.312260.json"
  },
  {
    "args": {
      "save": "../GLM/data/checkpoints/pretrain/blocklm-base-blank/ft_kd/RTE/blank-tiny6-RTE-221101_052036.510147",
      "epochs": 50,
      "iteration": 7800,
      "task": "RTE",
      "wsc_negative": false
    },
    "now": "2022-11-01 05:30:39.180702",
    "max_score_dict": {
      "accuracy": {
        "epoch": 3,
        "iteration": 624,
        "score_dict": {
          "accuracy": 52.707581227436826
        }
      }
    },
    "epoch": -1,
    "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=41166 --include=localhost:2,3 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-RTE-221101_052036.510147 --task=RTE --data-dir=../GLM/data/english_data/superglue/RTE --save=../GLM/data/checkpoints/pretrain/blocklm-base-blank/ft_kd/RTE --seq-length=256 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained= --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --pattern-id=0 --save-interval=10000 --log-interval=50 --eval-interval=10000000 --eval-iters=100 --batch-size=8 --epochs=50 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=tmp_deepspeed_config/221101_052036.511311_9768406128883668.json --student_model=kd --distill_ft_soft --distill_ft_hard --distill_temperature=10 --seed=1234 --teacher_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/RTE/blank-base-RTE-220813_065724 --teacher_num_layers=12 --teacher_hidden_size=768 --teacher_num_attention_heads=12 --teacher_max_position_embeddings=512 --teacher_fp16 --custom_tmp_result=../GLM/data/tmp/result_221101_052036.513638.json"
  },
  {
    "args": {
      "save": "../GLM/data/checkpoints/pretrain/blocklm-base-blank/ft_kd/BoolQ/blank-tiny6-BoolQ-221101_053042.176899",
      "epochs": 20,
      "iteration": 11800,
      "task": "BoolQ",
      "wsc_negative": false
    },
    "now": "2022-11-01 05:45:25.059787",
    "max_score_dict": {
      "accuracy": {
        "epoch": 4,
        "iteration": 2950,
        "score_dict": {
          "accuracy": 65.93272171253822
        }
      }
    },
    "epoch": -1,
    "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=17225 --include=localhost:2,3 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-BoolQ-221101_053042.176899 --task=BoolQ --data-dir=../GLM/data/english_data/superglue/BoolQ --save=../GLM/data/checkpoints/pretrain/blocklm-base-blank/ft_kd/BoolQ --seq-length=256 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained= --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --pattern-id=4 --save-interval=10000 --log-interval=50 --eval-interval=10000000 --eval-iters=100 --batch-size=8 --epochs=20 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=tmp_deepspeed_config/221101_053042.178192_38484888329825706.json --student_model=kd --distill_ft_soft --distill_ft_hard --distill_temperature=10 --seed=1234 --teacher_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/BoolQ/blank-base-BoolQ-220813_070712 --teacher_num_layers=12 --teacher_hidden_size=768 --teacher_num_attention_heads=12 --teacher_max_position_embeddings=512 --teacher_fp16 --custom_tmp_result=../GLM/data/tmp/result_221101_053042.179620.json"
  },
  {
    "args": {
      "save": "../GLM/data/checkpoints/pretrain/blocklm-base-blank/ft_kd/WiC/blank-tiny6-WiC-221101_054528.942365",
      "epochs": 30,
      "iteration": 10200,
      "task": "WiC",
      "wsc_negative": false
    },
    "now": "2022-11-01 05:58:42.532054",
    "max_score_dict": {
      "accuracy": {
        "epoch": 3,
        "iteration": 1360,
        "score_dict": {
          "accuracy": 55.79937304075235
        }
      }
    },
    "epoch": -1,
    "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=39368 --include=localhost:2,3 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-WiC-221101_054528.942365 --task=WiC --data-dir=../GLM/data/english_data/superglue/WiC --save=../GLM/data/checkpoints/pretrain/blocklm-base-blank/ft_kd/WiC --seq-length=256 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained= --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --pattern-id=1 --save-interval=10000 --log-interval=50 --eval-interval=10000000 --eval-iters=100 --batch-size=8 --epochs=30 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=tmp_deepspeed_config/221101_054528.942976_851830618095958.json --student_model=kd --distill_ft_soft --distill_ft_hard --distill_temperature=10 --seed=1234 --teacher_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/WiC/blank-base-WiC-220813_072213 --teacher_num_layers=12 --teacher_hidden_size=768 --teacher_num_attention_heads=12 --teacher_max_position_embeddings=512 --teacher_fp16 --custom_tmp_result=../GLM/data/tmp/result_221101_054528.944772.json"
  },
  {
    "args": {
      "save": "../GLM/data/checkpoints/pretrain/blocklm-base-blank/ft_kd/CB/blank-tiny6-CB-221101_055846.625900",
      "epochs": 50,
      "iteration": 800,
      "task": "CB",
      "wsc_negative": false
    },
    "now": "2022-11-01 06:01:09.317733",
    "max_score_dict": {
      "accuracy": {
        "epoch": 15,
        "iteration": 256,
        "score_dict": {
          "accuracy": 73.21428571428571,
          "f1-macro": 0.6026455026455027
        }
      },
      "f1-macro": {
        "epoch": 20,
        "iteration": 336,
        "score_dict": {
          "accuracy": 73.21428571428571,
          "f1-macro": 0.6425925925925926
        }
      }
    },
    "epoch": -1,
    "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=48536 --include=localhost:2,3 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-CB-221101_055846.625900 --task=CB --data-dir=../GLM/data/english_data/superglue/CB --save=../GLM/data/checkpoints/pretrain/blocklm-base-blank/ft_kd/CB --seq-length=256 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained= --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --pattern-id=3 --save-interval=10000 --log-interval=50 --eval-interval=10000000 --eval-iters=100 --batch-size=8 --epochs=50 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=tmp_deepspeed_config/221101_055846.627266_12688815592291613.json --student_model=kd --distill_ft_soft --distill_ft_hard --distill_temperature=10 --seed=1234 --teacher_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/CB/blank-base-CB-220813_065532 --teacher_num_layers=12 --teacher_hidden_size=768 --teacher_num_attention_heads=12 --teacher_max_position_embeddings=512 --teacher_fp16 --custom_tmp_result=../GLM/data/tmp/result_221101_055846.629495.json"
  },
  {
    "args": {
      "save": "../GLM/data/checkpoints/pretrain/blocklm-base-blank/ft_kd/MultiRC/blank-tiny6-MultiRC-221101_060112.763238",
      "epochs": 15,
      "iteration": 25545,
      "task": "MultiRC",
      "wsc_negative": false
    },
    "now": "2022-11-01 06:36:02.939249",
    "max_score_dict": {
      "f1a": {
        "epoch": 5,
        "iteration": 10218,
        "score_dict": {
          "f1a": 0.4713947990543736,
          "em": 0.030430220356768106,
          "acc": 53.87788778877888
        }
      },
      "em": {
        "epoch": 12,
        "iteration": 22139,
        "score_dict": {
          "f1a": 0.43861860347869924,
          "em": 0.03672612801678909,
          "acc": 54.06353135313531
        }
      },
      "acc": {
        "epoch": 3,
        "iteration": 6812,
        "score_dict": {
          "f1a": 0.26609442060085836,
          "em": 0.02098635886673662,
          "acc": 57.67326732673267
        }
      }
    },
    "epoch": -1,
    "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=28360 --include=localhost:2,3 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-MultiRC-221101_060112.763238 --task=MultiRC --data-dir=../GLM/data/english_data/superglue/MultiRC --save=../GLM/data/checkpoints/pretrain/blocklm-base-blank/ft_kd/MultiRC --seq-length=512 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained= --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --pattern-id=0 --save-interval=10000 --log-interval=50 --eval-interval=10000000 --eval-iters=100 --batch-size=8 --epochs=15 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=tmp_deepspeed_config/221101_060112.764447_7945156875295016.json --student_model=kd --distill_ft_soft --distill_ft_hard --distill_temperature=10 --seed=1234 --teacher_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/MultiRC/blank-base-MultiRC-220813_074014 --teacher_num_layers=12 --teacher_hidden_size=768 --teacher_num_attention_heads=12 --teacher_max_position_embeddings=512 --teacher_fp16 --custom_tmp_result=../GLM/data/tmp/result_221101_060112.766936.json"
  },
  {
    "args": {
      "save": "../GLM/data/checkpoints/pretrain/blocklm-base-blank/ft_kd/WSC/blank-tiny6-WSC_generative-221101_063606.044575",
      "epochs": 50,
      "iteration": 850,
      "task": "WSC",
      "wsc_negative": false
    },
    "now": "2022-11-01 06:37:51.213754",
    "max_score_dict": {
      "accuracy": {
        "epoch": 0,
        "iteration": 17,
        "score_dict": {
          "accuracy": 69.23076923076923
        }
      }
    },
    "epoch": -1,
    "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=26087 --include=localhost:2,3 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-WSC_generative-221101_063606.044575 --task=WSC --data-dir=../GLM/data/english_data/superglue/WSC --save=../GLM/data/checkpoints/pretrain/blocklm-base-blank/ft_kd/WSC --seq-length=128 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained= --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --save-interval=10000 --log-interval=50 --eval-interval=1000 --eval-iters=100 --batch-size=8 --epochs=50 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=tmp_deepspeed_config/221101_063606.047896_08353117084516937.json --student_model=kd --distill_ft_soft --distill_ft_hard --distill_temperature=10 --seed=1234 --teacher_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/WSC/blank-base-WSC_generative-220813_065345 --teacher_num_layers=12 --teacher_hidden_size=768 --teacher_num_attention_heads=12 --teacher_max_position_embeddings=512 --teacher_fp16 --custom_tmp_result=../GLM/data/tmp/result_221101_063606.050493.json"
  }
]