[
    {
      "args": {
        "save": "../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert/ft_tinybert/ReCoRD/blank-tiny6-ReCoRD-221106_230629.373956",
        "epochs": 5,
        "iteration": 43385,
        "task": "ReCoRD",
        "wsc_negative": false
      },
      "now": "2022-11-07 06:43:31.681780",
      "max_score_dict": {
        "EM": {
          "epoch": 3,
          "iteration": 34708,
          "score_dict": {
            "EM": 53.68,
            "F1": 54.82671428571435
          }
        },
        "F1": {
          "epoch": 3,
          "iteration": 34708,
          "score_dict": {
            "EM": 53.68,
            "F1": 54.82671428571435
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=14825 --include=localhost:4,5 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-ReCoRD-221106_230629.373956 --task=ReCoRD --data-dir=../GLM/data/english_data/superglue/ReCoRD --save=../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert/ft_tinybert/ReCoRD --seq-length=512 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained=../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --pattern-id=0 --save-interval=10000 --log-interval=50 --eval-interval=1000 --eval-iters=100 --batch-size=8 --epochs=5 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=tmp_deepspeed_config/221106_230630.477706_25834618801069653.json --student_model=tinybert --seed=1234 --teacher_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/ReCoRD/blank-base-ReCoRD-220813_083745 --teacher_num_layers=12 --teacher_hidden_size=768 --teacher_num_attention_heads=12 --teacher_max_position_embeddings=512 --teacher_fp16 --custom_tmp_result=../GLM/data/tmp/result_221106_230630.485945.json"
    },
    {
      "args": {
        "save": "../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert/ft_tinybert/ReCoRD/blank-tiny6-ReCoRD-221106_230629.373956/ft_tinybert/ReCoRD/blank-tiny6-ReCoRD-221106_230630.475001",
        "epochs": 5,
        "iteration": 43385,
        "task": "ReCoRD",
        "wsc_negative": false
      },
      "now": "2022-11-07 13:36:02.174056",
      "max_score_dict": {
        "EM": {
          "epoch": 4,
          "iteration": 43385,
          "score_dict": {
            "EM": 64.56,
            "F1": 65.32699350649357
          }
        },
        "F1": {
          "epoch": 4,
          "iteration": 43385,
          "score_dict": {
            "EM": 64.56,
            "F1": 65.32699350649357
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=25987 --include=localhost:4,5 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-ReCoRD-221106_230630.475001 --task=ReCoRD --data-dir=../GLM/data/english_data/superglue/ReCoRD --save=../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert/ft_tinybert/ReCoRD/blank-tiny6-ReCoRD-221106_230629.373956/ft_tinybert/ReCoRD --seq-length=512 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained=../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert/ft_tinybert/ReCoRD/blank-tiny6-ReCoRD-221106_230629.373956 --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --pattern-id=0 --save-interval=10000 --log-interval=50 --eval-interval=1000 --eval-iters=100 --batch-size=8 --epochs=5 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=tmp_deepspeed_config/221106_230630.482973_30378620576367377.json --teacher_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/ReCoRD/blank-base-ReCoRD-220813_083745 --teacher_num_layers=12 --teacher_hidden_size=768 --teacher_num_attention_heads=12 --teacher_max_position_embeddings=512 --teacher_fp16 --student_model=tinybert --seed=1234 --distill_ft_soft --tinybert_wo_inter --custom_first_eval --custom_tmp_result=../GLM/data/tmp/result_221107_064336.603449.json"
    },
    {
      "args": {
        "save": "../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert/ft_tinybert/COPA/blank-tiny6-COPA-221107_133606.870112",
        "epochs": 50,
        "iteration": 2500,
        "task": "COPA",
        "wsc_negative": false
      },
      "now": "2022-11-07 13:41:42.553425",
      "max_score_dict": {
        "accuracy": {
          "epoch": 2,
          "iteration": 150,
          "score_dict": {
            "accuracy": 63.0
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=36440 --include=localhost:4,5 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-COPA-221107_133606.870112 --task=COPA --data-dir=../GLM/data/english_data/superglue/COPA --save=../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert/ft_tinybert/COPA --seq-length=256 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained=../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --pattern-id=0 --save-interval=10000 --log-interval=20 --eval-interval=1000 --eval-iters=100 --batch-size=8 --epochs=50 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=tmp_deepspeed_config/221107_133608.003210_20269674973305585.json --student_model=tinybert --seed=1234 --teacher_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/COPA/blank-base-COPA-220813_064749 --teacher_num_layers=12 --teacher_hidden_size=768 --teacher_num_attention_heads=12 --teacher_max_position_embeddings=512 --teacher_fp16 --custom_tmp_result=../GLM/data/tmp/result_221107_133608.016039.json"
    },
    {
      "args": {
        "save": "../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert/ft_tinybert/COPA/blank-tiny6-COPA-221107_133606.870112/ft_tinybert/COPA/blank-tiny6-COPA-221107_133607.971090",
        "epochs": 50,
        "iteration": 2500,
        "task": "COPA",
        "wsc_negative": false
      },
      "now": "2022-11-07 13:46:39.094949",
      "max_score_dict": {
        "accuracy": {
          "epoch": 5,
          "iteration": 300,
          "score_dict": {
            "accuracy": 68.0
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=51812 --include=localhost:4,5 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-COPA-221107_133607.971090 --task=COPA --data-dir=../GLM/data/english_data/superglue/COPA --save=../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert/ft_tinybert/COPA/blank-tiny6-COPA-221107_133606.870112/ft_tinybert/COPA --seq-length=256 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained=../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert/ft_tinybert/COPA/blank-tiny6-COPA-221107_133606.870112 --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --pattern-id=0 --save-interval=10000 --log-interval=20 --eval-interval=1000 --eval-iters=100 --batch-size=8 --epochs=50 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=tmp_deepspeed_config/221107_133608.011246_6749801988355882.json --teacher_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/COPA/blank-base-COPA-220813_064749 --teacher_num_layers=12 --teacher_hidden_size=768 --teacher_num_attention_heads=12 --teacher_max_position_embeddings=512 --teacher_fp16 --student_model=tinybert --seed=1234 --distill_ft_soft --tinybert_wo_inter --custom_first_eval --custom_tmp_result=../GLM/data/tmp/result_221107_134146.626501.json"
    },
    {
      "args": {
        "save": "../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert/ft_tinybert/WSC/blank-tiny6-WSC-221107_134643.709817",
        "epochs": 50,
        "iteration": 1000,
        "task": "WSC",
        "wsc_negative": true
      },
      "now": "2022-11-07 13:50:54.136168",
      "max_score_dict": {
        "accuracy": {
          "epoch": 18,
          "iteration": 380,
          "score_dict": {
            "accuracy": 74.03846153846153
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=51955 --include=localhost:4,5 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-WSC-221107_134643.709817 --task=WSC --data-dir=../GLM/data/english_data/superglue/WSC-negative --save=../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert/ft_tinybert/WSC --seq-length=128 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained=../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --loss-func=mix --wsc-negative --length-penalty=1 --pattern-id=2 --save-interval=10000 --log-interval=50 --eval-interval=1000 --eval-iters=100 --batch-size=8 --epochs=50 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=tmp_deepspeed_config/221107_134644.813398_9836631414793472.json --student_model=tinybert --seed=1234 --teacher_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/WSC/blank-base-WSC-220813_073441 --teacher_num_layers=12 --teacher_hidden_size=768 --teacher_num_attention_heads=12 --teacher_max_position_embeddings=512 --teacher_fp16 --custom_tmp_result=../GLM/data/tmp/result_221107_134644.821438.json"
    },
    {
      "args": {
        "save": "../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert/ft_tinybert/WSC/blank-tiny6-WSC-221107_134643.709817/ft_tinybert/WSC/blank-tiny6-WSC-221107_134644.811726",
        "epochs": 50,
        "iteration": 1000,
        "task": "WSC",
        "wsc_negative": true
      },
      "now": "2022-11-07 13:54:51.448829",
      "max_score_dict": {
        "accuracy": {
          "epoch": 14,
          "iteration": 300,
          "score_dict": {
            "accuracy": 75.0
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=54009 --include=localhost:4,5 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-WSC-221107_134644.811726 --task=WSC --data-dir=../GLM/data/english_data/superglue/WSC-negative --save=../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert/ft_tinybert/WSC/blank-tiny6-WSC-221107_134643.709817/ft_tinybert/WSC --seq-length=128 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained=../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert/ft_tinybert/WSC/blank-tiny6-WSC-221107_134643.709817 --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --loss-func=mix --wsc-negative --length-penalty=1 --pattern-id=2 --save-interval=10000 --log-interval=50 --eval-interval=1000 --eval-iters=100 --batch-size=8 --epochs=50 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=tmp_deepspeed_config/221107_134644.818114_4594627985999624.json --teacher_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/WSC/blank-base-WSC-220813_073441 --teacher_num_layers=12 --teacher_hidden_size=768 --teacher_num_attention_heads=12 --teacher_max_position_embeddings=512 --teacher_fp16 --student_model=tinybert --seed=1234 --distill_ft_soft --tinybert_wo_inter --custom_first_eval --custom_tmp_result=../GLM/data/tmp/result_221107_135058.453730.json"
    },
    {
      "args": {
        "save": "../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert/ft_tinybert/RTE/blank-tiny6-RTE-221107_135454.649364",
        "epochs": 50,
        "iteration": 7800,
        "task": "RTE",
        "wsc_negative": false
      },
      "now": "2022-11-07 14:06:16.337816",
      "max_score_dict": {
        "accuracy": {
          "epoch": 32,
          "iteration": 5148,
          "score_dict": {
            "accuracy": 70.7581227436823
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=48993 --include=localhost:4,5 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-RTE-221107_135454.649364 --task=RTE --data-dir=../GLM/data/english_data/superglue/RTE --save=../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert/ft_tinybert/RTE --seq-length=256 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained=../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --pattern-id=0 --save-interval=10000 --log-interval=50 --eval-interval=10000000 --eval-iters=100 --batch-size=8 --epochs=50 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=tmp_deepspeed_config/221107_135455.752959_18467445019650042.json --student_model=tinybert --seed=1234 --teacher_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/RTE/blank-base-RTE-220813_065724 --teacher_num_layers=12 --teacher_hidden_size=768 --teacher_num_attention_heads=12 --teacher_max_position_embeddings=512 --teacher_fp16 --custom_tmp_result=../GLM/data/tmp/result_221107_135455.760161.json"
    },
    {
      "args": {
        "save": "../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert/ft_tinybert/RTE/blank-tiny6-RTE-221107_135454.649364/ft_tinybert/RTE/blank-tiny6-RTE-221107_135455.751330",
        "epochs": 50,
        "iteration": 7800,
        "task": "RTE",
        "wsc_negative": false
      },
      "now": "2022-11-07 14:16:14.174605",
      "max_score_dict": {
        "accuracy": {
          "epoch": 0,
          "iteration": 0,
          "score_dict": {
            "accuracy": 70.7581227436823
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=55938 --include=localhost:4,5 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-RTE-221107_135455.751330 --task=RTE --data-dir=../GLM/data/english_data/superglue/RTE --save=../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert/ft_tinybert/RTE/blank-tiny6-RTE-221107_135454.649364/ft_tinybert/RTE --seq-length=256 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained=../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert/ft_tinybert/RTE/blank-tiny6-RTE-221107_135454.649364 --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --pattern-id=0 --save-interval=10000 --log-interval=50 --eval-interval=10000000 --eval-iters=100 --batch-size=8 --epochs=50 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=tmp_deepspeed_config/221107_135455.756371_460309319090191.json --teacher_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/RTE/blank-base-RTE-220813_065724 --teacher_num_layers=12 --teacher_hidden_size=768 --teacher_num_attention_heads=12 --teacher_max_position_embeddings=512 --teacher_fp16 --student_model=tinybert --seed=1234 --distill_ft_soft --tinybert_wo_inter --custom_first_eval --custom_tmp_result=../GLM/data/tmp/result_221107_140620.635955.json"
    },
    {
      "args": {
        "save": "../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert/ft_tinybert/BoolQ/blank-tiny6-BoolQ-221107_141619.033659",
        "epochs": 20,
        "iteration": 11800,
        "task": "BoolQ",
        "wsc_negative": false
      },
      "now": "2022-11-07 14:32:34.550953",
      "max_score_dict": {
        "accuracy": {
          "epoch": 9,
          "iteration": 5900,
          "score_dict": {
            "accuracy": 77.92048929663609
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=34825 --include=localhost:4,5 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-BoolQ-221107_141619.033659 --task=BoolQ --data-dir=../GLM/data/english_data/superglue/BoolQ --save=../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert/ft_tinybert/BoolQ --seq-length=256 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained=../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --pattern-id=4 --save-interval=10000 --log-interval=50 --eval-interval=10000000 --eval-iters=100 --batch-size=8 --epochs=20 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=tmp_deepspeed_config/221107_141620.164126_24832793362504824.json --student_model=tinybert --seed=1234 --teacher_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/BoolQ/blank-base-BoolQ-220813_070712 --teacher_num_layers=12 --teacher_hidden_size=768 --teacher_num_attention_heads=12 --teacher_max_position_embeddings=512 --teacher_fp16 --custom_tmp_result=../GLM/data/tmp/result_221107_141620.182949.json"
    },
    {
      "args": {
        "save": "../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert/ft_tinybert/BoolQ/blank-tiny6-BoolQ-221107_141619.033659/ft_tinybert/BoolQ/blank-tiny6-BoolQ-221107_141620.134983",
        "epochs": 20,
        "iteration": 11800,
        "task": "BoolQ",
        "wsc_negative": false
      },
      "now": "2022-11-07 14:47:17.407452",
      "max_score_dict": {
        "accuracy": {
          "epoch": 12,
          "iteration": 7670,
          "score_dict": {
            "accuracy": 78.34862385321101
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=14905 --include=localhost:4,5 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-BoolQ-221107_141620.134983 --task=BoolQ --data-dir=../GLM/data/english_data/superglue/BoolQ --save=../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert/ft_tinybert/BoolQ/blank-tiny6-BoolQ-221107_141619.033659/ft_tinybert/BoolQ --seq-length=256 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained=../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert/ft_tinybert/BoolQ/blank-tiny6-BoolQ-221107_141619.033659 --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --pattern-id=4 --save-interval=10000 --log-interval=50 --eval-interval=10000000 --eval-iters=100 --batch-size=8 --epochs=20 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=tmp_deepspeed_config/221107_141620.171208_9023444987709598.json --teacher_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/BoolQ/blank-base-BoolQ-220813_070712 --teacher_num_layers=12 --teacher_hidden_size=768 --teacher_num_attention_heads=12 --teacher_max_position_embeddings=512 --teacher_fp16 --student_model=tinybert --seed=1234 --distill_ft_soft --tinybert_wo_inter --custom_first_eval --custom_tmp_result=../GLM/data/tmp/result_221107_143238.757902.json"
    },
    {
      "args": {
        "save": "../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert/ft_tinybert/WiC/blank-tiny6-WiC-221107_144722.790483",
        "epochs": 30,
        "iteration": 10200,
        "task": "WiC",
        "wsc_negative": false
      },
      "now": "2022-11-07 15:01:23.244535",
      "max_score_dict": {
        "accuracy": {
          "epoch": 4,
          "iteration": 1700,
          "score_dict": {
            "accuracy": 67.55485893416927
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=13460 --include=localhost:4,5 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-WiC-221107_144722.790483 --task=WiC --data-dir=../GLM/data/english_data/superglue/WiC --save=../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert/ft_tinybert/WiC --seq-length=256 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained=../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --pattern-id=1 --save-interval=10000 --log-interval=50 --eval-interval=10000000 --eval-iters=100 --batch-size=8 --epochs=30 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=tmp_deepspeed_config/221107_144723.894219_7446292479270389.json --student_model=tinybert --seed=1234 --teacher_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/WiC/blank-base-WiC-220813_072213 --teacher_num_layers=12 --teacher_hidden_size=768 --teacher_num_attention_heads=12 --teacher_max_position_embeddings=512 --teacher_fp16 --custom_tmp_result=../GLM/data/tmp/result_221107_144723.899557.json"
    },
    {
      "args": {
        "save": "../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert/ft_tinybert/WiC/blank-tiny6-WiC-221107_144722.790483/ft_tinybert/WiC/blank-tiny6-WiC-221107_144723.892221",
        "epochs": 30,
        "iteration": 10200,
        "task": "WiC",
        "wsc_negative": false
      },
      "now": "2022-11-07 15:14:11.276130",
      "max_score_dict": {
        "accuracy": {
          "epoch": 0,
          "iteration": 0,
          "score_dict": {
            "accuracy": 67.55485893416927
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=30842 --include=localhost:4,5 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-WiC-221107_144723.892221 --task=WiC --data-dir=../GLM/data/english_data/superglue/WiC --save=../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert/ft_tinybert/WiC/blank-tiny6-WiC-221107_144722.790483/ft_tinybert/WiC --seq-length=256 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained=../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert/ft_tinybert/WiC/blank-tiny6-WiC-221107_144722.790483 --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --pattern-id=1 --save-interval=10000 --log-interval=50 --eval-interval=10000000 --eval-iters=100 --batch-size=8 --epochs=30 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=tmp_deepspeed_config/221107_144723.897461_5012424064621691.json --teacher_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/WiC/blank-base-WiC-220813_072213 --teacher_num_layers=12 --teacher_hidden_size=768 --teacher_num_attention_heads=12 --teacher_max_position_embeddings=512 --teacher_fp16 --student_model=tinybert --seed=1234 --distill_ft_soft --tinybert_wo_inter --custom_first_eval --custom_tmp_result=../GLM/data/tmp/result_221107_150129.288080.json"
    },
    {
      "args": {
        "save": "../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert/ft_tinybert/CB/blank-tiny6-CB-221107_151414.084547",
        "epochs": 50,
        "iteration": 800,
        "task": "CB",
        "wsc_negative": false
      },
      "now": "2022-11-07 15:16:39.106990",
      "max_score_dict": {
        "accuracy": {
          "epoch": 31,
          "iteration": 512,
          "score_dict": {
            "accuracy": 83.92857142857143,
            "f1-macro": 0.8139506172839507
          }
        },
        "f1-macro": {
          "epoch": 31,
          "iteration": 512,
          "score_dict": {
            "accuracy": 83.92857142857143,
            "f1-macro": 0.8139506172839507
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=37625 --include=localhost:4,5 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-CB-221107_151414.084547 --task=CB --data-dir=../GLM/data/english_data/superglue/CB --save=../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert/ft_tinybert/CB --seq-length=256 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained=../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --pattern-id=3 --save-interval=10000 --log-interval=50 --eval-interval=10000000 --eval-iters=100 --batch-size=8 --epochs=50 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=tmp_deepspeed_config/221107_151415.187015_7738270005618095.json --student_model=tinybert --seed=1234 --teacher_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/CB/blank-base-CB-220813_065532 --teacher_num_layers=12 --teacher_hidden_size=768 --teacher_num_attention_heads=12 --teacher_max_position_embeddings=512 --teacher_fp16 --custom_tmp_result=../GLM/data/tmp/result_221107_151415.191039.json"
    },
    {
      "args": {
        "save": "../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert/ft_tinybert/CB/blank-tiny6-CB-221107_151414.084547/ft_tinybert/CB/blank-tiny6-CB-221107_151415.186089",
        "epochs": 50,
        "iteration": 800,
        "task": "CB",
        "wsc_negative": false
      },
      "now": "2022-11-07 15:19:12.221335",
      "max_score_dict": {
        "accuracy": {
          "epoch": 11,
          "iteration": 192,
          "score_dict": {
            "accuracy": 91.07142857142857,
            "f1-macro": 0.9047376896347149
          }
        },
        "f1-macro": {
          "epoch": 11,
          "iteration": 192,
          "score_dict": {
            "accuracy": 91.07142857142857,
            "f1-macro": 0.9047376896347149
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=55130 --include=localhost:4,5 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-CB-221107_151415.186089 --task=CB --data-dir=../GLM/data/english_data/superglue/CB --save=../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert/ft_tinybert/CB/blank-tiny6-CB-221107_151414.084547/ft_tinybert/CB --seq-length=256 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained=../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert/ft_tinybert/CB/blank-tiny6-CB-221107_151414.084547 --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --pattern-id=3 --save-interval=10000 --log-interval=50 --eval-interval=10000000 --eval-iters=100 --batch-size=8 --epochs=50 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=tmp_deepspeed_config/221107_151415.189705_1845647931526756.json --teacher_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/CB/blank-base-CB-220813_065532 --teacher_num_layers=12 --teacher_hidden_size=768 --teacher_num_attention_heads=12 --teacher_max_position_embeddings=512 --teacher_fp16 --student_model=tinybert --seed=1234 --distill_ft_soft --tinybert_wo_inter --custom_first_eval --custom_tmp_result=../GLM/data/tmp/result_221107_151642.980037.json"
    },
    {
      "args": {
        "save": "../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert/ft_tinybert/MultiRC/blank-tiny6-MultiRC-221107_151914.867652",
        "epochs": 15,
        "iteration": 25545,
        "task": "MultiRC",
        "wsc_negative": false
      },
      "now": "2022-11-07 15:59:49.814313",
      "max_score_dict": {
        "f1a": {
          "epoch": 8,
          "iteration": 15327,
          "score_dict": {
            "f1a": 0.7123227917121047,
            "em": 0.2518363064008394,
            "acc": 72.79290429042905
          }
        },
        "em": {
          "epoch": 5,
          "iteration": 10218,
          "score_dict": {
            "f1a": 0.7107952021323856,
            "em": 0.2633788037775446,
            "acc": 73.14356435643565
          }
        },
        "acc": {
          "epoch": 7,
          "iteration": 13624,
          "score_dict": {
            "f1a": 0.7089804186360568,
            "em": 0.2528856243441763,
            "acc": 73.32920792079207
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=15691 --include=localhost:4,5 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-MultiRC-221107_151914.867652 --task=MultiRC --data-dir=../GLM/data/english_data/superglue/MultiRC --save=../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert/ft_tinybert/MultiRC --seq-length=512 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained=../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --pattern-id=0 --save-interval=10000 --log-interval=50 --eval-interval=10000000 --eval-iters=100 --batch-size=8 --epochs=15 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=tmp_deepspeed_config/221107_151915.970921_3718982800028562.json --student_model=tinybert --seed=1234 --teacher_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/MultiRC/blank-base-MultiRC-220813_074014 --teacher_num_layers=12 --teacher_hidden_size=768 --teacher_num_attention_heads=12 --teacher_max_position_embeddings=512 --teacher_fp16 --custom_tmp_result=../GLM/data/tmp/result_221107_151915.976518.json"
    },
    {
      "args": {
        "save": "../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert/ft_tinybert/MultiRC/blank-tiny6-MultiRC-221107_151914.867652/ft_tinybert/MultiRC/blank-tiny6-MultiRC-221107_151915.969300",
        "epochs": 15,
        "iteration": 25545,
        "task": "MultiRC",
        "wsc_negative": false
      },
      "now": "2022-11-07 16:35:35.672425",
      "max_score_dict": {
        "f1a": {
          "epoch": 12,
          "iteration": 22139,
          "score_dict": {
            "f1a": 0.7159709618874773,
            "em": 0.25918153200419725,
            "acc": 74.17491749174917
          }
        },
        "em": {
          "epoch": 12,
          "iteration": 22139,
          "score_dict": {
            "f1a": 0.7159709618874773,
            "em": 0.25918153200419725,
            "acc": 74.17491749174917
          }
        },
        "acc": {
          "epoch": 13,
          "iteration": 23842,
          "score_dict": {
            "f1a": 0.7080890973036342,
            "em": 0.25813221406086045,
            "acc": 74.31930693069307
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=16594 --include=localhost:4,5 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-MultiRC-221107_151915.969300 --task=MultiRC --data-dir=../GLM/data/english_data/superglue/MultiRC --save=../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert/ft_tinybert/MultiRC/blank-tiny6-MultiRC-221107_151914.867652/ft_tinybert/MultiRC --seq-length=512 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained=../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert/ft_tinybert/MultiRC/blank-tiny6-MultiRC-221107_151914.867652 --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --pattern-id=0 --save-interval=10000 --log-interval=50 --eval-interval=10000000 --eval-iters=100 --batch-size=8 --epochs=15 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=tmp_deepspeed_config/221107_151915.974482_5112063528552245.json --teacher_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/MultiRC/blank-base-MultiRC-220813_074014 --teacher_num_layers=12 --teacher_hidden_size=768 --teacher_num_attention_heads=12 --teacher_max_position_embeddings=512 --teacher_fp16 --student_model=tinybert --seed=1234 --distill_ft_soft --tinybert_wo_inter --custom_first_eval --custom_tmp_result=../GLM/data/tmp/result_221107_155955.015754.json"
    },
    {
      "args": {
        "save": "../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert/ft_tinybert/WSC/blank-tiny6-WSC_generative-221107_163539.658666",
        "epochs": 50,
        "iteration": 850,
        "task": "WSC",
        "wsc_negative": false
      },
      "now": "2022-11-07 16:37:44.418546",
      "max_score_dict": {
        "accuracy": {
          "epoch": 0,
          "iteration": 17,
          "score_dict": {
            "accuracy": 69.23076923076923
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=56504 --include=localhost:4,5 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-WSC_generative-221107_163539.658666 --task=WSC --data-dir=../GLM/data/english_data/superglue/WSC --save=../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert/ft_tinybert/WSC --seq-length=128 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained=../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --save-interval=10000 --log-interval=50 --eval-interval=1000 --eval-iters=100 --batch-size=8 --epochs=50 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=tmp_deepspeed_config/221107_163540.778962_01747622203459598.json --student_model=tinybert --seed=1234 --teacher_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/WSC/blank-base-WSC_generative-220813_065345 --teacher_num_layers=12 --teacher_hidden_size=768 --teacher_num_attention_heads=12 --teacher_max_position_embeddings=512 --teacher_fp16 --custom_tmp_result=../GLM/data/tmp/result_221107_163540.795025.json"
    },
    {
      "args": {
        "save": "../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert/ft_tinybert/WSC/blank-tiny6-WSC_generative-221107_163539.658666/ft_tinybert/WSC/blank-tiny6-WSC_generative-221107_163540.760088",
        "epochs": 50,
        "iteration": 850,
        "task": "WSC",
        "wsc_negative": false
      },
      "now": "2022-11-07 16:39:47.044565",
      "max_score_dict": {
        "accuracy": {
          "epoch": 29,
          "iteration": 510,
          "score_dict": {
            "accuracy": 82.6923076923077
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=16242 --include=localhost:4,5 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-WSC_generative-221107_163540.760088 --task=WSC --data-dir=../GLM/data/english_data/superglue/WSC --save=../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert/ft_tinybert/WSC/blank-tiny6-WSC_generative-221107_163539.658666/ft_tinybert/WSC --seq-length=128 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained=../GLM/data/checkpoints/distill/paper/12.768-6.768_64-15w_tinybert/ft_tinybert/WSC/blank-tiny6-WSC_generative-221107_163539.658666 --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --save-interval=10000 --log-interval=50 --eval-interval=1000 --eval-iters=100 --batch-size=8 --epochs=50 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=tmp_deepspeed_config/221107_163540.791442_5463150997087726.json --teacher_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/WSC/blank-base-WSC_generative-220813_065345 --teacher_num_layers=12 --teacher_hidden_size=768 --teacher_num_attention_heads=12 --teacher_max_position_embeddings=512 --teacher_fp16 --student_model=tinybert --seed=1234 --distill_ft_soft --tinybert_wo_inter --custom_first_eval --custom_tmp_result=../GLM/data/tmp/result_221107_163749.297548.json"
    }
  ]