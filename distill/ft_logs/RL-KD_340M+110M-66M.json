[
    {
      "args": {
        "save": "../GLM/data/checkpoints/pretrain/block_tiny6/ft_rlkd/ReCoRD/blank-tiny6-ReCoRD-221230_233709.001344",
        "epochs": 5,
        "iteration": 43385,
        "task": "ReCoRD",
        "wsc_negative": false
      },
      "now": "2022-12-31 21:00:11.228799",
      "max_score_dict": {
        "EM": {
          "epoch": 4,
          "iteration": 43385,
          "score_dict": {
            "EM": 58.97,
            "F1": 59.73392857142863
          }
        },
        "F1": {
          "epoch": 4,
          "iteration": 43385,
          "score_dict": {
            "EM": 58.97,
            "F1": 59.73392857142863
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=11534 --include=localhost:6 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-ReCoRD-221230_233709.001344 --task=ReCoRD --data-dir=../GLM/data/english_data/superglue/ReCoRD --save=../GLM/data/checkpoints/pretrain/block_tiny6/ft_rlkd/ReCoRD --seq-length=512 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained= --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --pattern-id=0 --save-interval=10000 --log-interval=50 --eval-interval=1000 --eval-iters=100 --batch-size=16 --epochs=5 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=config_tasks/config_blocklm_tiny6.json --student_model=kd --distill_ft_soft --distill_temperature=10 --student_truncate_tn=0 --multi_teacher_model=rl_kd --rl_kd_only_avg --rl_kd_alpha=0.5 --rl_kd_semantic_model_dim=768 --seed=1234 --mt_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/ReCoRD/blank-base-ReCoRD-220813_083745:../GLM/data/checkpoints/pretrain/blocklm-large-blank/finetune/ReCoRD/blank-large-ReCoRD-220813_190003 --mt_num_layers=12:24 --mt_hidden_size=768:1024 --mt_num_attention_heads=12:16 --mt_max_position_embeddings=512:512 --teacher_fp16 --custom_tmp_result=../GLM/data/tmp/result_221230_233710.107648.json"
    },
    {
      "args": {
        "save": "../GLM/data/checkpoints/pretrain/block_tiny6/ft_rlkd/ReCoRD/blank-tiny6-ReCoRD-221230_233709.001344/ft_rlkd/ReCoRD/blank-tiny6-ReCoRD-221230_233710.103188",
        "epochs": 5,
        "iteration": 43385,
        "task": "ReCoRD",
        "wsc_negative": false
      },
      "now": "2023-01-01 22:06:13.543704",
      "max_score_dict": {
        "EM": {
          "epoch": 0,
          "iteration": 0,
          "score_dict": {
            "EM": 58.97,
            "F1": 59.73392857142863
          }
        },
        "F1": {
          "epoch": 0,
          "iteration": 0,
          "score_dict": {
            "EM": 58.97,
            "F1": 59.73392857142863
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=31694 --include=localhost:6 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-ReCoRD-221230_233710.103188 --task=ReCoRD --data-dir=../GLM/data/english_data/superglue/ReCoRD --save=../GLM/data/checkpoints/pretrain/block_tiny6/ft_rlkd/ReCoRD/blank-tiny6-ReCoRD-221230_233709.001344/ft_rlkd/ReCoRD --seq-length=512 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained=../GLM/data/checkpoints/pretrain/block_tiny6/ft_rlkd/ReCoRD/blank-tiny6-ReCoRD-221230_233709.001344 --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --pattern-id=0 --save-interval=10000 --log-interval=50 --eval-interval=1000 --eval-iters=100 --batch-size=16 --epochs=5 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=config_tasks/config_blocklm_tiny6.json --mt_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank:../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/ReCoRD/blank-base-ReCoRD-220813_083745:../GLM/data/checkpoints/pretrain/blocklm-large-blank/finetune/ReCoRD/blank-large-ReCoRD-220813_190003 --mt_num_layers=12:12:24 --mt_hidden_size=768:768:1024 --mt_num_attention_heads=12:12:16 --mt_max_position_embeddings=512:512:512 --teacher_fp16 --student_model=kd --distill_ft_soft --distill_temperature=10 --multi_teacher_model=rl_kd --rl_kd_alpha=0.5 --rl_kd_semantic_model_dim=768 --seed=1234 --rl_kd_reward=1 --rl_kd_semantic_model=0 --mt_has_loss --custom_first_eval --custom_tmp_result=../GLM/data/tmp/result_221231_210014.190141.json"
    },
    {
      "args": {
        "save": "../GLM/data/checkpoints/pretrain/block_tiny6/ft_rlkd/COPA/blank-tiny6-COPA-230101_220619.065556",
        "epochs": 50,
        "iteration": 2500,
        "task": "COPA",
        "wsc_negative": false
      },
      "now": "2023-01-01 22:15:58.214798",
      "max_score_dict": {
        "accuracy": {
          "epoch": 19,
          "iteration": 1000,
          "score_dict": {
            "accuracy": 58.0
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=29600 --include=localhost:6 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-COPA-230101_220619.065556 --task=COPA --data-dir=../GLM/data/english_data/superglue/COPA --save=../GLM/data/checkpoints/pretrain/block_tiny6/ft_rlkd/COPA --seq-length=256 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained= --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --pattern-id=0 --save-interval=10000 --log-interval=20 --eval-interval=1000 --eval-iters=100 --batch-size=16 --epochs=50 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=config_tasks/config_blocklm_tiny6.json --student_model=kd --distill_ft_soft --distill_temperature=10 --student_truncate_tn=0 --multi_teacher_model=rl_kd --rl_kd_only_avg --rl_kd_alpha=0.5 --rl_kd_semantic_model_dim=768 --seed=1234 --mt_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/COPA/blank-base-COPA-220813_064749:../GLM/data/checkpoints/pretrain/blocklm-large-blank/finetune/COPA/blank-large-COPA-220813_123629 --mt_num_layers=12:24 --mt_hidden_size=768:1024 --mt_num_attention_heads=12:16 --mt_max_position_embeddings=512:512 --teacher_fp16 --custom_tmp_result=../GLM/data/tmp/result_230101_220620.175526.json"
    },
    {
      "args": {
        "save": "../GLM/data/checkpoints/pretrain/block_tiny6/ft_rlkd/COPA/blank-tiny6-COPA-230101_220619.065556/ft_rlkd/COPA/blank-tiny6-COPA-230101_220620.167442",
        "epochs": 50,
        "iteration": 2500,
        "task": "COPA",
        "wsc_negative": false
      },
      "now": "2023-01-01 22:26:33.920024",
      "max_score_dict": {
        "accuracy": {
          "epoch": 2,
          "iteration": 150,
          "score_dict": {
            "accuracy": 59.0
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=25005 --include=localhost:6 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-COPA-230101_220620.167442 --task=COPA --data-dir=../GLM/data/english_data/superglue/COPA --save=../GLM/data/checkpoints/pretrain/block_tiny6/ft_rlkd/COPA/blank-tiny6-COPA-230101_220619.065556/ft_rlkd/COPA --seq-length=256 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained=../GLM/data/checkpoints/pretrain/block_tiny6/ft_rlkd/COPA/blank-tiny6-COPA-230101_220619.065556 --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --pattern-id=0 --save-interval=10000 --log-interval=20 --eval-interval=1000 --eval-iters=100 --batch-size=16 --epochs=50 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=config_tasks/config_blocklm_tiny6.json --mt_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank:../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/COPA/blank-base-COPA-220813_064749:../GLM/data/checkpoints/pretrain/blocklm-large-blank/finetune/COPA/blank-large-COPA-220813_123629 --mt_num_layers=12:12:24 --mt_hidden_size=768:768:1024 --mt_num_attention_heads=12:12:16 --mt_max_position_embeddings=512:512:512 --teacher_fp16 --student_model=kd --distill_ft_soft --distill_temperature=10 --multi_teacher_model=rl_kd --rl_kd_alpha=0.5 --rl_kd_semantic_model_dim=768 --seed=1234 --rl_kd_reward=1 --rl_kd_semantic_model=0 --mt_has_loss --custom_first_eval --custom_tmp_result=../GLM/data/tmp/result_230101_221602.350696.json"
    },
    {
      "args": {
        "save": "../GLM/data/checkpoints/pretrain/block_tiny6/ft_rlkd/WSC/blank-tiny6-WSC-230101_222636.840052",
        "epochs": 50,
        "iteration": 1000,
        "task": "WSC",
        "wsc_negative": true
      },
      "now": "2023-01-01 22:34:09.544847",
      "max_score_dict": {
        "accuracy": {
          "epoch": 3,
          "iteration": 80,
          "score_dict": {
            "accuracy": 65.38461538461539
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=11912 --include=localhost:6 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-WSC-230101_222636.840052 --task=WSC --data-dir=../GLM/data/english_data/superglue/WSC-negative --save=../GLM/data/checkpoints/pretrain/block_tiny6/ft_rlkd/WSC --seq-length=128 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained= --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --loss-func=mix --wsc-negative --length-penalty=1 --pattern-id=2 --save-interval=10000 --log-interval=50 --eval-interval=1000 --eval-iters=100 --batch-size=16 --epochs=50 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=config_tasks/config_blocklm_tiny6.json --student_model=kd --distill_ft_soft --distill_temperature=10 --student_truncate_tn=0 --multi_teacher_model=rl_kd --rl_kd_only_avg --rl_kd_alpha=0.5 --rl_kd_semantic_model_dim=768 --seed=1234 --mt_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/WSC/blank-base-WSC-220813_073441:../GLM/data/checkpoints/pretrain/blocklm-large-blank/finetune/WSC/blank-large-WSC-220813_150605 --mt_num_layers=12:24 --mt_hidden_size=768:1024 --mt_num_attention_heads=12:16 --mt_max_position_embeddings=512:512 --teacher_fp16 --custom_tmp_result=../GLM/data/tmp/result_230101_222637.944650.json"
    },
    {
      "args": {
        "save": "../GLM/data/checkpoints/pretrain/block_tiny6/ft_rlkd/WSC/blank-tiny6-WSC-230101_222636.840052/ft_rlkd/WSC/blank-tiny6-WSC-230101_222637.941974",
        "epochs": 50,
        "iteration": 1000,
        "task": "WSC",
        "wsc_negative": true
      },
      "now": "2023-01-01 22:42:50.664065",
      "max_score_dict": {
        "accuracy": {
          "epoch": 0,
          "iteration": 0,
          "score_dict": {
            "accuracy": 65.38461538461539
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=20717 --include=localhost:6 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-WSC-230101_222637.941974 --task=WSC --data-dir=../GLM/data/english_data/superglue/WSC-negative --save=../GLM/data/checkpoints/pretrain/block_tiny6/ft_rlkd/WSC/blank-tiny6-WSC-230101_222636.840052/ft_rlkd/WSC --seq-length=128 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained=../GLM/data/checkpoints/pretrain/block_tiny6/ft_rlkd/WSC/blank-tiny6-WSC-230101_222636.840052 --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --loss-func=mix --wsc-negative --length-penalty=1 --pattern-id=2 --save-interval=10000 --log-interval=50 --eval-interval=1000 --eval-iters=100 --batch-size=16 --epochs=50 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=config_tasks/config_blocklm_tiny6.json --mt_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank:../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/WSC/blank-base-WSC-220813_073441:../GLM/data/checkpoints/pretrain/blocklm-large-blank/finetune/WSC/blank-large-WSC-220813_150605 --mt_num_layers=12:12:24 --mt_hidden_size=768:768:1024 --mt_num_attention_heads=12:12:16 --mt_max_position_embeddings=512:512:512 --teacher_fp16 --student_model=kd --distill_ft_soft --distill_temperature=10 --multi_teacher_model=rl_kd --rl_kd_alpha=0.5 --rl_kd_semantic_model_dim=768 --seed=1234 --rl_kd_reward=1 --rl_kd_semantic_model=0 --mt_has_loss --custom_first_eval --custom_tmp_result=../GLM/data/tmp/result_230101_223412.793293.json"
    },
    {
      "args": {
        "save": "../GLM/data/checkpoints/pretrain/block_tiny6/ft_rlkd/RTE/blank-tiny6-RTE-230102_005745.766362",
        "epochs": 50,
        "iteration": 7800,
        "task": "RTE",
        "wsc_negative": false
      },
      "now": "2023-01-02 01:13:58.399018",
      "max_score_dict": {
        "accuracy": {
          "epoch": 7,
          "iteration": 1248,
          "score_dict": {
            "accuracy": 67.14801444043322
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=21878 --include=localhost:6 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-RTE-230102_005745.766362 --task=RTE --data-dir=../GLM/data/english_data/superglue/RTE --save=../GLM/data/checkpoints/pretrain/block_tiny6/ft_rlkd/RTE --seq-length=256 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained= --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --pattern-id=0 --save-interval=10000 --log-interval=50 --eval-interval=10000000 --eval-iters=100 --batch-size=16 --epochs=50 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=config_tasks/config_blocklm_tiny6.json --student_model=kd --distill_ft_soft --distill_temperature=10 --student_truncate_tn=0 --multi_teacher_model=rl_kd --rl_kd_only_avg --rl_kd_alpha=0.5 --rl_kd_semantic_model_dim=768 --seed=1234 --mt_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/RTE/blank-base-RTE-220813_065724:../GLM/data/checkpoints/pretrain/blocklm-large-blank/finetune/RTE/blank-large-RTE-220813_130259 --mt_num_layers=12:24 --mt_hidden_size=768:1024 --mt_num_attention_heads=12:16 --mt_max_position_embeddings=512:512 --teacher_fp16 --custom_tmp_result=../GLM/data/tmp/result_230102_005746.871515.json"
    },
    {
      "args": {
        "save": "../GLM/data/checkpoints/pretrain/block_tiny6/ft_rlkd/RTE/blank-tiny6-RTE-230102_005745.766362/ft_rlkd/RTE/blank-tiny6-RTE-230102_005746.867982",
        "epochs": 50,
        "iteration": 7800,
        "task": "RTE",
        "wsc_negative": false
      },
      "now": "2023-01-02 01:32:19.060685",
      "max_score_dict": {
        "accuracy": {
          "epoch": 24,
          "iteration": 3900,
          "score_dict": {
            "accuracy": 68.23104693140795
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=36039 --include=localhost:6 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-RTE-230102_005746.867982 --task=RTE --data-dir=../GLM/data/english_data/superglue/RTE --save=../GLM/data/checkpoints/pretrain/block_tiny6/ft_rlkd/RTE/blank-tiny6-RTE-230102_005745.766362/ft_rlkd/RTE --seq-length=256 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained=../GLM/data/checkpoints/pretrain/block_tiny6/ft_rlkd/RTE/blank-tiny6-RTE-230102_005745.766362 --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --pattern-id=0 --save-interval=10000 --log-interval=50 --eval-interval=10000000 --eval-iters=100 --batch-size=16 --epochs=50 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=config_tasks/config_blocklm_tiny6.json --mt_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank:../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/RTE/blank-base-RTE-220813_065724:../GLM/data/checkpoints/pretrain/blocklm-large-blank/finetune/RTE/blank-large-RTE-220813_130259 --mt_num_layers=12:12:24 --mt_hidden_size=768:768:1024 --mt_num_attention_heads=12:12:16 --mt_max_position_embeddings=512:512:512 --teacher_fp16 --student_model=kd --distill_ft_soft --distill_temperature=10 --multi_teacher_model=rl_kd --rl_kd_alpha=0.5 --rl_kd_semantic_model_dim=768 --seed=1234 --rl_kd_reward=1 --rl_kd_semantic_model=0 --mt_has_loss --custom_first_eval --custom_tmp_result=../GLM/data/tmp/result_230102_011402.775774.json"
    },
    {
      "args": {
        "save": "../GLM/data/checkpoints/pretrain/block_tiny6/ft_rlkd/BoolQ/blank-tiny6-BoolQ-230102_114550.935425",
        "epochs": 20,
        "iteration": 11800,
        "task": "BoolQ",
        "wsc_negative": false
      },
      "now": "2023-01-02 12:10:43.567646",
      "max_score_dict": {
        "accuracy": {
          "epoch": 15,
          "iteration": 9440,
          "score_dict": {
            "accuracy": 77.58409785932722
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=59543 --include=localhost:6 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-BoolQ-230102_114550.935425 --task=BoolQ --data-dir=../GLM/data/english_data/superglue/BoolQ --save=../GLM/data/checkpoints/pretrain/block_tiny6/ft_rlkd/BoolQ --seq-length=256 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained= --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --pattern-id=4 --save-interval=10000 --log-interval=50 --eval-interval=10000000 --eval-iters=100 --batch-size=16 --epochs=20 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=config_tasks/config_blocklm_tiny6.json --student_model=kd --distill_ft_soft --distill_temperature=10 --student_truncate_tn=0 --multi_teacher_model=rl_kd --rl_kd_only_avg --rl_kd_alpha=0.5 --rl_kd_semantic_model_dim=768 --seed=1234 --mt_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/BoolQ/blank-base-BoolQ-220813_070712:../GLM/data/checkpoints/pretrain/blocklm-large-blank/finetune/BoolQ/blank-large-BoolQ-220813_133458 --mt_num_layers=12:24 --mt_hidden_size=768:1024 --mt_num_attention_heads=12:16 --mt_max_position_embeddings=512:512 --teacher_fp16 --custom_tmp_result=../GLM/data/tmp/result_230102_114552.041876.json"
    },
    {
      "args": {
        "save": "../GLM/data/checkpoints/pretrain/block_tiny6/ft_rlkd/BoolQ/blank-tiny6-BoolQ-230102_114550.935425/ft_rlkd/BoolQ/blank-tiny6-BoolQ-230102_114552.036975",
        "epochs": 20,
        "iteration": 11800,
        "task": "BoolQ",
        "wsc_negative": false
      },
      "now": "2023-01-02 12:37:58.813410",
      "max_score_dict": {
        "accuracy": {
          "epoch": 0,
          "iteration": 0,
          "score_dict": {
            "accuracy": 77.58409785932722
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=47923 --include=localhost:6 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-BoolQ-230102_114552.036975 --task=BoolQ --data-dir=../GLM/data/english_data/superglue/BoolQ --save=../GLM/data/checkpoints/pretrain/block_tiny6/ft_rlkd/BoolQ/blank-tiny6-BoolQ-230102_114550.935425/ft_rlkd/BoolQ --seq-length=256 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained=../GLM/data/checkpoints/pretrain/block_tiny6/ft_rlkd/BoolQ/blank-tiny6-BoolQ-230102_114550.935425 --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --pattern-id=4 --save-interval=10000 --log-interval=50 --eval-interval=10000000 --eval-iters=100 --batch-size=16 --epochs=20 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=config_tasks/config_blocklm_tiny6.json --mt_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank:../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/BoolQ/blank-base-BoolQ-220813_070712:../GLM/data/checkpoints/pretrain/blocklm-large-blank/finetune/BoolQ/blank-large-BoolQ-220813_133458 --mt_num_layers=12:12:24 --mt_hidden_size=768:768:1024 --mt_num_attention_heads=12:12:16 --mt_max_position_embeddings=512:512:512 --teacher_fp16 --student_model=kd --distill_ft_soft --distill_temperature=10 --multi_teacher_model=rl_kd --rl_kd_alpha=0.5 --rl_kd_semantic_model_dim=768 --seed=1234 --rl_kd_reward=1 --rl_kd_semantic_model=0 --mt_has_loss --custom_first_eval --custom_tmp_result=../GLM/data/tmp/result_230102_121047.045413.json"
    },
    {
      "args": {
        "save": "../GLM/data/checkpoints/pretrain/block_tiny6/ft_rlkd/WiC/blank-tiny6-WiC-230102_123801.913989",
        "epochs": 30,
        "iteration": 10200,
        "task": "WiC",
        "wsc_negative": false
      },
      "now": "2023-01-02 12:58:47.356224",
      "max_score_dict": {
        "accuracy": {
          "epoch": 4,
          "iteration": 1700,
          "score_dict": {
            "accuracy": 66.77115987460814
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=33114 --include=localhost:6 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-WiC-230102_123801.913989 --task=WiC --data-dir=../GLM/data/english_data/superglue/WiC --save=../GLM/data/checkpoints/pretrain/block_tiny6/ft_rlkd/WiC --seq-length=256 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained= --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --pattern-id=1 --save-interval=10000 --log-interval=50 --eval-interval=10000000 --eval-iters=100 --batch-size=16 --epochs=30 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=config_tasks/config_blocklm_tiny6.json --student_model=kd --distill_ft_soft --distill_temperature=10 --student_truncate_tn=0 --multi_teacher_model=rl_kd --rl_kd_only_avg --rl_kd_alpha=0.5 --rl_kd_semantic_model_dim=768 --seed=1234 --mt_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/WiC/blank-base-WiC-220813_072213:../GLM/data/checkpoints/pretrain/blocklm-large-blank/finetune/WiC/blank-large-WiC-220813_142454 --mt_num_layers=12:24 --mt_hidden_size=768:1024 --mt_num_attention_heads=12:16 --mt_max_position_embeddings=512:512 --teacher_fp16 --custom_tmp_result=../GLM/data/tmp/result_230102_123803.018515.json"
    },
    {
      "args": {
        "save": "../GLM/data/checkpoints/pretrain/block_tiny6/ft_rlkd/WiC/blank-tiny6-WiC-230102_123801.913989/ft_rlkd/WiC/blank-tiny6-WiC-230102_123803.015993",
        "epochs": 30,
        "iteration": 10200,
        "task": "WiC",
        "wsc_negative": false
      },
      "now": "2023-01-02 13:22:23.439039",
      "max_score_dict": {
        "accuracy": {
          "epoch": 0,
          "iteration": 0,
          "score_dict": {
            "accuracy": 66.77115987460814
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=41296 --include=localhost:6 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-WiC-230102_123803.015993 --task=WiC --data-dir=../GLM/data/english_data/superglue/WiC --save=../GLM/data/checkpoints/pretrain/block_tiny6/ft_rlkd/WiC/blank-tiny6-WiC-230102_123801.913989/ft_rlkd/WiC --seq-length=256 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained=../GLM/data/checkpoints/pretrain/block_tiny6/ft_rlkd/WiC/blank-tiny6-WiC-230102_123801.913989 --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --pattern-id=1 --save-interval=10000 --log-interval=50 --eval-interval=10000000 --eval-iters=100 --batch-size=16 --epochs=30 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=config_tasks/config_blocklm_tiny6.json --mt_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank:../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/WiC/blank-base-WiC-220813_072213:../GLM/data/checkpoints/pretrain/blocklm-large-blank/finetune/WiC/blank-large-WiC-220813_142454 --mt_num_layers=12:12:24 --mt_hidden_size=768:768:1024 --mt_num_attention_heads=12:12:16 --mt_max_position_embeddings=512:512:512 --teacher_fp16 --student_model=kd --distill_ft_soft --distill_temperature=10 --multi_teacher_model=rl_kd --rl_kd_alpha=0.5 --rl_kd_semantic_model_dim=768 --seed=1234 --rl_kd_reward=1 --rl_kd_semantic_model=0 --mt_has_loss --custom_first_eval --custom_tmp_result=../GLM/data/tmp/result_230102_125851.883188.json"
    },
    {
      "args": {
        "save": "../GLM/data/checkpoints/pretrain/block_tiny6/ft_rlkd/CB/blank-tiny6-CB-230102_132227.520553",
        "epochs": 50,
        "iteration": 800,
        "task": "CB",
        "wsc_negative": false
      },
      "now": "2023-01-02 13:25:04.915663",
      "max_score_dict": {
        "accuracy": {
          "epoch": 19,
          "iteration": 320,
          "score_dict": {
            "accuracy": 82.14285714285714,
            "f1-macro": 0.7482442710991227
          }
        },
        "f1-macro": {
          "epoch": 19,
          "iteration": 320,
          "score_dict": {
            "accuracy": 82.14285714285714,
            "f1-macro": 0.7482442710991227
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=55660 --include=localhost:6 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-CB-230102_132227.520553 --task=CB --data-dir=../GLM/data/english_data/superglue/CB --save=../GLM/data/checkpoints/pretrain/block_tiny6/ft_rlkd/CB --seq-length=256 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained= --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --pattern-id=3 --save-interval=10000 --log-interval=50 --eval-interval=10000000 --eval-iters=100 --batch-size=16 --epochs=50 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=config_tasks/config_blocklm_tiny6.json --student_model=kd --distill_ft_soft --distill_temperature=10 --student_truncate_tn=0 --multi_teacher_model=rl_kd --rl_kd_only_avg --rl_kd_alpha=0.5 --rl_kd_semantic_model_dim=768 --seed=1234 --mt_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/CB/blank-base-CB-220813_065532:../GLM/data/checkpoints/pretrain/blocklm-large-blank/finetune/CB/blank-large-CB-220813_125843 --mt_num_layers=12:24 --mt_hidden_size=768:1024 --mt_num_attention_heads=12:16 --mt_max_position_embeddings=512:512 --teacher_fp16 --custom_tmp_result=../GLM/data/tmp/result_230102_132228.624846.json"
    },
    {
      "args": {
        "save": "../GLM/data/checkpoints/pretrain/block_tiny6/ft_rlkd/CB/blank-tiny6-CB-230102_132227.520553/ft_rlkd/CB/blank-tiny6-CB-230102_132228.622422",
        "epochs": 50,
        "iteration": 800,
        "task": "CB",
        "wsc_negative": false
      },
      "now": "2023-01-02 13:27:57.290405",
      "max_score_dict": {
        "accuracy": {
          "epoch": 0,
          "iteration": 0,
          "score_dict": {
            "accuracy": 82.14285714285714,
            "f1-macro": 0.7482442710991227
          }
        },
        "f1-macro": {
          "epoch": 0,
          "iteration": 0,
          "score_dict": {
            "accuracy": 82.14285714285714,
            "f1-macro": 0.7482442710991227
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=18828 --include=localhost:6 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-CB-230102_132228.622422 --task=CB --data-dir=../GLM/data/english_data/superglue/CB --save=../GLM/data/checkpoints/pretrain/block_tiny6/ft_rlkd/CB/blank-tiny6-CB-230102_132227.520553/ft_rlkd/CB --seq-length=256 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained=../GLM/data/checkpoints/pretrain/block_tiny6/ft_rlkd/CB/blank-tiny6-CB-230102_132227.520553 --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --pattern-id=3 --save-interval=10000 --log-interval=50 --eval-interval=10000000 --eval-iters=100 --batch-size=16 --epochs=50 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=config_tasks/config_blocklm_tiny6.json --mt_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank:../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/CB/blank-base-CB-220813_065532:../GLM/data/checkpoints/pretrain/blocklm-large-blank/finetune/CB/blank-large-CB-220813_125843 --mt_num_layers=12:12:24 --mt_hidden_size=768:768:1024 --mt_num_attention_heads=12:12:16 --mt_max_position_embeddings=512:512:512 --teacher_fp16 --student_model=kd --distill_ft_soft --distill_temperature=10 --multi_teacher_model=rl_kd --rl_kd_alpha=0.5 --rl_kd_semantic_model_dim=768 --seed=1234 --rl_kd_reward=1 --rl_kd_semantic_model=0 --mt_has_loss --custom_first_eval --custom_tmp_result=../GLM/data/tmp/result_230102_132507.423572.json"
    },
    {
      "args": {
        "save": "../GLM/data/checkpoints/pretrain/block_tiny6/ft_rlkd/MultiRC/blank-tiny6-MultiRC-230102_132801.435998",
        "epochs": 15,
        "iteration": 25545,
        "task": "MultiRC",
        "wsc_negative": false
      },
      "now": "2023-01-02 14:59:46.623365",
      "max_score_dict": {
        "f1a": {
          "epoch": 8,
          "iteration": 15327,
          "score_dict": {
            "f1a": 0.7029430446749947,
            "em": 0.2088142707240294,
            "acc": 71.0602310231023
          }
        },
        "em": {
          "epoch": 14,
          "iteration": 25545,
          "score_dict": {
            "f1a": 0.697939500219202,
            "em": 0.229800629590766,
            "acc": 71.57590759075907
          }
        },
        "acc": {
          "epoch": 4,
          "iteration": 8515,
          "score_dict": {
            "f1a": 0.6766666666666666,
            "em": 0.2214060860440714,
            "acc": 71.98844884488449
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=46506 --include=localhost:6 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-MultiRC-230102_132801.435998 --task=MultiRC --data-dir=../GLM/data/english_data/superglue/MultiRC --save=../GLM/data/checkpoints/pretrain/block_tiny6/ft_rlkd/MultiRC --seq-length=512 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained= --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --pattern-id=0 --save-interval=10000 --log-interval=50 --eval-interval=10000000 --eval-iters=100 --batch-size=16 --epochs=15 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=config_tasks/config_blocklm_tiny6.json --student_model=kd --distill_ft_soft --distill_temperature=10 --student_truncate_tn=0 --multi_teacher_model=rl_kd --rl_kd_only_avg --rl_kd_alpha=0.5 --rl_kd_semantic_model_dim=768 --seed=1234 --mt_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/MultiRC/blank-base-MultiRC-220813_074014:../GLM/data/checkpoints/pretrain/blocklm-large-blank/finetune/MultiRC/blank-large-MultiRC-220813_152437 --mt_num_layers=12:24 --mt_hidden_size=768:1024 --mt_num_attention_heads=12:16 --mt_max_position_embeddings=512:512 --teacher_fp16 --custom_tmp_result=../GLM/data/tmp/result_230102_132802.539586.json"
    },
    {
      "args": {
        "save": "../GLM/data/checkpoints/pretrain/block_tiny6/ft_rlkd/MultiRC/blank-tiny6-MultiRC-230102_132801.435998/ft_rlkd/MultiRC/blank-tiny6-MultiRC-230102_132802.537266",
        "epochs": 15,
        "iteration": 25545,
        "task": "MultiRC",
        "wsc_negative": false
      },
      "now": "2023-01-02 16:44:55.290222",
      "max_score_dict": {
        "f1a": {
          "epoch": 0,
          "iteration": 0,
          "score_dict": {
            "f1a": 0.7029430446749947,
            "em": 0.2088142707240294,
            "acc": 71.0602310231023
          }
        },
        "em": {
          "epoch": 4,
          "iteration": 8515,
          "score_dict": {
            "f1a": 0.695250659630607,
            "em": 0.23294858342077648,
            "acc": 71.41089108910892
          }
        },
        "acc": {
          "epoch": 0,
          "iteration": 1703,
          "score_dict": {
            "f1a": 0.692813420992972,
            "em": 0.2214060860440714,
            "acc": 72.0503300330033
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=37885 --include=localhost:6 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-MultiRC-230102_132802.537266 --task=MultiRC --data-dir=../GLM/data/english_data/superglue/MultiRC --save=../GLM/data/checkpoints/pretrain/block_tiny6/ft_rlkd/MultiRC/blank-tiny6-MultiRC-230102_132801.435998/ft_rlkd/MultiRC --seq-length=512 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained=../GLM/data/checkpoints/pretrain/block_tiny6/ft_rlkd/MultiRC/blank-tiny6-MultiRC-230102_132801.435998 --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --pattern-id=0 --save-interval=10000 --log-interval=50 --eval-interval=10000000 --eval-iters=100 --batch-size=16 --epochs=15 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=config_tasks/config_blocklm_tiny6.json --mt_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank:../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/MultiRC/blank-base-MultiRC-220813_074014:../GLM/data/checkpoints/pretrain/blocklm-large-blank/finetune/MultiRC/blank-large-MultiRC-220813_152437 --mt_num_layers=12:12:24 --mt_hidden_size=768:768:1024 --mt_num_attention_heads=12:12:16 --mt_max_position_embeddings=512:512:512 --teacher_fp16 --student_model=kd --distill_ft_soft --distill_temperature=10 --multi_teacher_model=rl_kd --rl_kd_alpha=0.5 --rl_kd_semantic_model_dim=768 --seed=1234 --rl_kd_reward=1 --rl_kd_semantic_model=0 --mt_has_loss --custom_first_eval --custom_tmp_result=../GLM/data/tmp/result_230102_145950.584847.json"
    },
    {
      "args": {
        "save": "../GLM/data/checkpoints/pretrain/block_tiny6/ft_rlkd/WSC/blank-tiny6-WSC_generative-230102_164459.572524",
        "epochs": 50,
        "iteration": 850,
        "task": "WSC",
        "wsc_negative": false
      },
      "now": "2023-01-02 16:47:34.846862",
      "max_score_dict": {
        "accuracy": {
          "epoch": 11,
          "iteration": 204,
          "score_dict": {
            "accuracy": 65.38461538461539
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=56798 --include=localhost:6 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-WSC_generative-230102_164459.572524 --task=WSC --data-dir=../GLM/data/english_data/superglue/WSC --save=../GLM/data/checkpoints/pretrain/block_tiny6/ft_rlkd/WSC --seq-length=128 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained= --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --save-interval=10000 --log-interval=50 --eval-interval=1000 --eval-iters=100 --batch-size=16 --epochs=50 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=config_tasks/config_blocklm_tiny6.json --student_model=kd --distill_ft_soft --distill_temperature=10 --student_truncate_tn=0 --multi_teacher_model=rl_kd --rl_kd_only_avg --rl_kd_alpha=0.5 --rl_kd_semantic_model_dim=768 --seed=1234 --mt_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/WSC/blank-base-WSC_generative-220813_065345:../GLM/data/checkpoints/pretrain/blocklm-large-blank/finetune/WSC/blank-large-WSC_generative-220813_125540 --mt_num_layers=12:24 --mt_hidden_size=768:1024 --mt_num_attention_heads=12:16 --mt_max_position_embeddings=512:512 --teacher_fp16 --custom_tmp_result=../GLM/data/tmp/result_230102_164500.675778.json"
    },
    {
      "args": {
        "save": "../GLM/data/checkpoints/pretrain/block_tiny6/ft_rlkd/WSC/blank-tiny6-WSC_generative-230102_164459.572524/ft_rlkd/WSC/blank-tiny6-WSC_generative-230102_164500.674183",
        "epochs": 50,
        "iteration": 850,
        "task": "WSC",
        "wsc_negative": false
      },
      "now": "2023-01-02 16:50:24.569260",
      "max_score_dict": {
        "accuracy": {
          "epoch": 15,
          "iteration": 272,
          "score_dict": {
            "accuracy": 66.34615384615384
          }
        }
      },
      "epoch": -1,
      "*cmd": "NCCL_DEBUG=info NCCL_IB_DISABLE=0 NCCL_NET_GDR_LEVEL=2 deepspeed --master_port=43544 --include=localhost:6 --hostfile= distill/finetune.py --finetune --cloze-eval --experiment-name=blank-tiny6-WSC_generative-230102_164500.674183 --task=WSC --data-dir=../GLM/data/english_data/superglue/WSC --save=../GLM/data/checkpoints/pretrain/block_tiny6/ft_rlkd/WSC/blank-tiny6-WSC_generative-230102_164459.572524/ft_rlkd/WSC --seq-length=128 --checkpoint-activations --eval-batch-size=16 --save-epoch=100000 --block-lm --num-layers=6 --hidden-size=768 --num-attention-heads=12 --max-position-embeddings=512 --tokenizer-model-type=bert-base-uncased --tokenizer-type=BertWordPieceTokenizer --load-pretrained=../GLM/data/checkpoints/pretrain/block_tiny6/ft_rlkd/WSC/blank-tiny6-WSC_generative-230102_164459.572524 --fp16 --lr-decay-style=linear --warmup=0.1 --weight-decay=1.0e-1 --save-interval=10000 --log-interval=50 --eval-interval=1000 --eval-iters=100 --batch-size=16 --epochs=50 --lr=1e-5 --overwrite --deepspeed-activation-checkpointing --deepspeed --deepspeed_config=config_tasks/config_blocklm_tiny6.json --mt_load_pretrained=../GLM/data/checkpoints/pretrain/blocklm-base-blank:../GLM/data/checkpoints/pretrain/blocklm-base-blank/finetune/WSC/blank-base-WSC_generative-220813_065345:../GLM/data/checkpoints/pretrain/blocklm-large-blank/finetune/WSC/blank-large-WSC_generative-220813_125540 --mt_num_layers=12:12:24 --mt_hidden_size=768:768:1024 --mt_num_attention_heads=12:12:16 --mt_max_position_embeddings=512:512:512 --teacher_fp16 --student_model=kd --distill_ft_soft --distill_temperature=10 --multi_teacher_model=rl_kd --rl_kd_alpha=0.5 --rl_kd_semantic_model_dim=768 --seed=1234 --rl_kd_reward=1 --rl_kd_semantic_model=0 --mt_has_loss --custom_first_eval --custom_tmp_result=../GLM/data/tmp/result_230102_164737.675646.json"
    }
  ]